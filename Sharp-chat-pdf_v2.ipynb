{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector:  7\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './pickleDump/vector_store.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 63\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vector_store\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# directory_path = \"./Document/test\"\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mdocument_chunker_langchain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Document/test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# print(vector_store)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Querying the vector store\u001b[39;00m\n\u001b[0;32m     68\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbulb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 58\u001b[0m, in \u001b[0;36mdocument_chunker_langchain\u001b[1;34m(directory_path, model_name, chunk_size, chunk_overlap)\u001b[0m\n\u001b[0;32m     55\u001b[0m document \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39mdocstore\u001b[38;5;241m.\u001b[39m_dict[doc_id]\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# print(f\"Metadata: {document.metadata}\")\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# print('list(vector_store.docstore._dict.keys())[i]',list(vector_store.docstore._dict.keys())[i])\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(vector_store, \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./pickleDump/vector_store.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vector_store\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './pickleDump/vector_store.pkl'"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "import pickle\n",
    "import uuid\n",
    "\n",
    "def document_chunker_langchain(directory_path,\n",
    "                                model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                                chunk_size=1024,\n",
    "                                chunk_overlap=0):\n",
    "    \"\"\"\n",
    "    Processes files in a directory, chunks text based on the model's tokenization constraints, and\n",
    "    prepares a vector store with the text chunks and metadata using LangChain.\n",
    "    \"\"\"\n",
    "    # Initialize embeddings model and text splitter\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "    documents = []  # List to hold all documents\n",
    "\n",
    "    # Iterate through files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            base = os.path.basename(file_path)\n",
    "            sku = os.path.splitext(base)[0]\n",
    "\n",
    "            \n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                text = file.read()\n",
    "\n",
    "            # Split text into manageable chunks\n",
    "            chunks = text_splitter.split_text(text)\n",
    "\n",
    "            # Create Document objects with metadata\n",
    "            for chunk in chunks:\n",
    "                doc = Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\"file_name\": sku}\n",
    "                )\n",
    "                documents.append(doc)\n",
    "\n",
    "    # Build a vector store from the documents\n",
    "    i = 1\n",
    "    # print(documents[i].page_content)\n",
    "    vector_store = FAISS.from_documents(documents, embeddings)\n",
    "    num_vectors = vector_store.index.ntotal\n",
    "\n",
    "    # recon = vector_store.index.reconstruct(i)\n",
    "    # recon = vector_store.index\n",
    "    print('Vector: ',num_vectors)\n",
    "    doc_id = list(vector_store.docstore._dict.keys())[i]\n",
    "    document = vector_store.docstore._dict[doc_id]\n",
    "    # print(f\"Metadata: {document.metadata}\")\n",
    "    # print('list(vector_store.docstore._dict.keys())[i]',list(vector_store.docstore._dict.keys())[i])\n",
    "    pickle.dump(vector_store, open(\"./pickleDump/vector_store.pkl\", \"wb\"))\n",
    "    return vector_store\n",
    "\n",
    "# Example usage\n",
    "# directory_path = \"./Document/test\"\n",
    "vector_store = document_chunker_langchain(\"./Document/test\")\n",
    "\n",
    "\n",
    "# print(vector_store)\n",
    "# Querying the vector store\n",
    "query = \"bulb\"\n",
    "results = vector_store.similarity_search(query, k=5)\n",
    "# viecpickle.load(open(\"./pickleDump/vector_store.pkl\", \"rb\"))\n",
    "\n",
    "# for result in results:\n",
    "#     print(f\"Text: {result.page_content}\\nMetadata: {result.metadata}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(system_prompt, retrieved_docs, user_query):\n",
    "    prompt = f\"\"\"{system_prompt}\n",
    "\n",
    "    Here is the retrieved context:\n",
    "    {retrieved_docs}\n",
    "\n",
    "    Here is the users query:\n",
    "    {user_query}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an intelligent search engine. You will be provided with some retrieved context, as well as the users query.\n",
    "\n",
    "Your job is to understand the request, and answer based on the retrieved context.\n",
    "\"\"\"\n",
    "\n",
    "retrieved_docs = \"\"\"\n",
    "Wall-mounted electric fireplace with realistic LED flames and heat settings. Features a black glass frame and remote control for easy operation. Ideal for adding warmth and ambiance. Manufactured by Hearth & Home. Dimensions: 50\"W x 6\"D x 21\"H.\n",
    "\"\"\"\n",
    "\n",
    "prompt = construct_prompt(system_prompt=system_prompt,\n",
    "                          retrieved_docs=retrieved_docs,\n",
    "                          user_query=\"bulb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM MESSAGE:\n",
      "\n",
      "You are an intelligent search engine. You will be provided with some retrieved context, as well as the users query.\n",
      "\n",
      "Your job is to understand the request, and answer based on the retrieved context.\n",
      "\n",
      "\n",
      "HUMAN MESSAGE:\n",
      "\n",
      "                                Here is the retrieved context:\n",
      "                                \n",
      "Wall-mounted electric fireplace with realistic LED flames and heat settings. Features a black glass frame and remote control for easy operation. Ideal for adding warmth and ambiance. Manufactured by Hearth & Home. Dimensions: 50\"W x 6\"D x 21\"H.\n",
      "\n",
      "\n",
      "                                Here is the user's query:\n",
      "                                What are the dimensions of the fireplace?\n",
      "                                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "def construct_prompt(system_prompt, retrieved_docs, user_query):\n",
    "    # Define the system message prompt\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    \n",
    "    # Define the human message prompt with placeholders\n",
    "    human_message = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "                                Here is the retrieved context:\n",
    "                                {retrieved_docs}\n",
    "\n",
    "                                Here is the user's query:\n",
    "                                {user_query}\n",
    "                                    \"\"\")\n",
    "    \n",
    "    # Combine the system and human messages into a ChatPromptTemplate\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    \n",
    "    # Format the chat prompt with the provided inputs\n",
    "    formatted_prompt = chat_prompt.format_messages(\n",
    "        retrieved_docs=retrieved_docs,\n",
    "        user_query=user_query\n",
    "    )\n",
    "    \n",
    "    return formatted_prompt\n",
    "\n",
    "# Inputs\n",
    "system_prompt = \"\"\"\n",
    "You are an intelligent search engine. You will be provided with some retrieved context, as well as the users query.\n",
    "\n",
    "Your job is to understand the request, and answer based on the retrieved context.\n",
    "\"\"\"\n",
    "\n",
    "retrieved_docs = \"\"\"\n",
    "Wall-mounted electric fireplace with realistic LED flames and heat settings. Features a black glass frame and remote control for easy operation. Ideal for adding warmth and ambiance. Manufactured by Hearth & Home. Dimensions: 50\"W x 6\"D x 21\"H.\n",
    "\"\"\"\n",
    "\n",
    "user_query = \"What are the dimensions of the fireplace?\"\n",
    "\n",
    "# Generate the prompt\n",
    "formatted_prompt = construct_prompt(system_prompt, retrieved_docs, user_query)\n",
    "# Display the formatted prompt\n",
    "for message in formatted_prompt:\n",
    "    print(f\"{message.type.upper()} MESSAGE:\")\n",
    "    print(message.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2149946735.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    chmod +x TinyLlama-1.1B-Chat-v1.0.Q5_K_M.llamafile\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "chmod +x TinyLlama-1.1B-Chat-v1.0.Q5_K_M.llamafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1414495550.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    ollama run tinyllama\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'formatted_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs)\n\u001b[0;32m     12\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOllama(\n\u001b[0;32m     13\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtinyllama\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m chain \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\"\u001b[39m: format_docs} \u001b[38;5;241m|\u001b[39m \u001b[43mformatted_prompt\u001b[49m \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# messages = [\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#     (\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#         \"system\",\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#     (\"human\", \"I love programming.\"),\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[0;32m     28\u001b[0m results \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39msimilarity_search(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbulb\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'formatted_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"tinyllama\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "chain = {\"docs\": format_docs} | formatted_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "# messages = [\n",
    "#     (\n",
    "#         \"system\",\n",
    "#         \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "#     ),\n",
    "#     (\"human\", \"I love programming.\"),\n",
    "# ]\n",
    "\n",
    "results = vector_store.similarity_search(\"bulb\", k=5)\n",
    "\n",
    "chain.invoke(results)\n",
    "\n",
    "# llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'dict' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_docs\u001b[39m(docs):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs)\n\u001b[1;32m---> 15\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_docs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mformatted_prompt\u001b[49m \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[0;32m     17\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the approaches to Task Decomposition?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m results \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39msimilarity_search(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'dict' and 'list'"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Convert loaded documents into strings by concatenating their content\n",
    "# and ignoring metadata\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "chain = {\"docs\": format_docs} | formatted_prompt | llm | StrOutputParser()\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "results = vector_store.similarity_search(question, k=5)\n",
    "\n",
    "chain.invoke(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (3897215599.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    wget https://huggingface.co/jartine/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/TinyLlama-1.1B-Chat-v1.0.Q5_K_M.exe\u001b[0m\n\u001b[1;37m                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "wget https://huggingface.co/jartine/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/TinyLlama-1.1B-Chat-v1.0.Q5_K_M.llamafile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vector content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 0a44b13f-57c5-4b0d-aff5-8f9328554fc8\n",
      "document_content: page_content='{\n",
      "  \"MBR-2001\": \"Traditional sleigh bed crafted in rich walnut wood, featuring a curved headboard and footboard with intricate grain details. Queen size, includes a plush, supportive mattress. Produced by Heritage Bed Co. Dimensions: 65\\\"W x 85\\\"L x 50\\\"H.\",\n",
      "  \"MBR-2002\": \"Art Deco-inspired vanity table in a polished ebony finish, featuring a tri-fold mirror and five drawers with crystal knobs. Includes a matching stool upholstered in silver velvet. Made by Luxe Interiors. Vanity dimensions: 48\\\"W x 20\\\"D x 30\\\"H, Stool dimensions: 22\\\"W x 16\\\"D x 18\\\"H.\",\n",
      "  \"MBR-2003\": \"Set of sheer linen drapes in soft ivory, offering a delicate and airy touch to bedroom windows. Each panel measures 54\\\"W x 84\\\"L. Features hidden tabs for easy hanging. Manufactured by Tranquil Home Textiles.\",' metadata={'file_name': 'test_data'}\n",
      "Metadata: {'file_name': 'test_data'}\n",
      "Vector: [ 2.96612475e-02 -4.58519533e-02  2.86810286e-02  4.08276878e-02\n",
      " -1.88260176e-03  3.03939171e-02 -4.29465668e-03 -2.25108583e-03\n",
      " -3.06164660e-02  2.94195618e-02 -9.15238783e-02 -2.31756996e-02\n",
      "  4.46774960e-02 -7.33868405e-02 -6.53316230e-02  7.44550489e-03\n",
      "  5.47292866e-02 -3.96066196e-02 -2.24098749e-02  1.22100443e-01\n",
      "  4.75485586e-02 -6.46831170e-02  2.41980515e-02 -2.27175769e-03\n",
      " -2.63093188e-02  1.48524856e-02 -7.55043048e-03  2.08084602e-02\n",
      " -3.04304417e-02 -6.09704219e-02  8.03156942e-02  2.46805921e-02\n",
      "  4.03004996e-02 -5.11862629e-04  4.54888754e-02 -2.67272219e-02\n",
      "  3.10673192e-03 -5.58897248e-03  1.77330747e-02 -2.46394575e-02\n",
      " -6.53366223e-02 -7.36193359e-02  3.25535121e-03  4.75411601e-02\n",
      "  3.34328786e-02  3.13979648e-02 -3.70497094e-03 -2.10150220e-02\n",
      " -6.06024377e-02  5.35362517e-04  1.39879510e-02 -6.24203030e-03\n",
      " -1.06886318e-02  3.71868201e-02 -7.53002102e-03 -3.82437749e-04\n",
      " -4.12557013e-02 -7.44810700e-02  3.79432552e-02 -7.34739080e-02\n",
      "  2.32513174e-02  3.08915209e-02  2.60952320e-02 -3.25582102e-02\n",
      "  1.28715823e-03  3.92064936e-02 -7.66177997e-02 -1.74551364e-02\n",
      " -7.67450873e-03 -3.74405943e-02 -5.11001423e-02 -1.22970082e-02\n",
      " -6.11543991e-02  6.24752343e-02 -5.27113006e-02 -5.53617068e-02\n",
      "  4.20376286e-02 -4.56607342e-02 -2.47288663e-02  5.61645515e-02\n",
      " -1.15564413e-01  9.14896280e-02  2.85848845e-02  5.07429317e-02\n",
      " -4.42682356e-02 -3.76148596e-02  1.81960966e-02  3.00852209e-02\n",
      " -3.67983282e-02 -8.36156756e-02  3.49141993e-02 -1.36302961e-02\n",
      " -1.84977837e-02  1.67021491e-02 -1.22409919e-02 -1.32320996e-03\n",
      " -1.57329347e-02  3.35064903e-02  7.97066614e-02  3.06429472e-02\n",
      " -4.70762625e-02  5.79749793e-02  7.20321313e-02  1.10886339e-02\n",
      " -6.12571128e-02 -5.69745824e-02  3.61969732e-02  7.74431154e-02\n",
      " -1.50020169e-02 -4.90902029e-02 -7.64766410e-02 -3.25133726e-02\n",
      " -2.26522274e-02  7.35320002e-02  2.38630734e-02 -9.75720286e-02\n",
      "  2.34623943e-02 -1.75548289e-02  7.59073719e-02 -6.41266704e-02\n",
      "  1.12051338e-01  7.70037770e-02  2.28810753e-03  7.82633293e-03\n",
      " -9.16799754e-02 -4.34024222e-02  3.81330922e-02  4.86955918e-33\n",
      "  1.40480613e-02  2.48055533e-02  6.94611594e-02  1.73920728e-02\n",
      "  8.36190134e-02  1.53022241e-02  1.07395900e-02  7.13258162e-02\n",
      "  2.76135821e-02  1.66864648e-01 -2.22637150e-02 -3.39570679e-02\n",
      " -6.07864512e-03  3.48475133e-03  1.02313729e-02  5.21881878e-02\n",
      " -3.13207731e-02  1.42700307e-03 -2.04729717e-02  2.66000498e-02\n",
      " -2.79292241e-02  6.11840487e-02  6.90578222e-02  4.79007512e-02\n",
      " -9.71323997e-03 -7.32569909e-03  3.33687216e-02 -1.06517524e-02\n",
      " -1.84531871e-03 -4.36476199e-03  5.39636090e-02 -1.11716799e-01\n",
      "  8.78539868e-03 -5.51785827e-02 -9.69250128e-02 -6.26019761e-02\n",
      " -2.65496802e-02 -5.47598628e-03 -3.07887364e-02  2.99024470e-02\n",
      " -2.69686505e-02  1.31033035e-02  5.10243773e-02  7.21517578e-02\n",
      "  2.94775353e-03  7.95783177e-02  6.39295876e-02  1.58314779e-02\n",
      "  3.65349613e-02  1.04330545e-02 -3.87621224e-02  2.13190578e-02\n",
      " -4.00285758e-02  1.75385363e-02 -1.48156257e-02 -5.73457778e-02\n",
      " -3.35644744e-02  4.20901924e-03  7.28456154e-02  8.88105556e-02\n",
      "  6.67875260e-02  1.34457117e-02  2.16362849e-02 -8.05210099e-02\n",
      "  8.85218661e-03 -1.38703296e-02  4.05622721e-02  7.33409729e-03\n",
      " -1.66363735e-02 -3.27251218e-02 -6.30821884e-02 -1.78178474e-02\n",
      "  5.70505671e-02  3.59134451e-02 -1.30735859e-02 -1.00410627e-02\n",
      " -5.31486832e-02 -6.48929253e-02  7.22823199e-03 -2.63947770e-02\n",
      " -2.21349206e-02  4.61094193e-02 -1.46240937e-02 -8.55537225e-03\n",
      " -4.55605872e-02 -6.80118501e-02  3.89788370e-03 -4.53128181e-02\n",
      " -7.55648687e-02 -5.04681729e-02 -3.75833325e-02 -2.84825992e-02\n",
      " -4.83904369e-02 -2.37068845e-04 -8.02761689e-02 -5.61942760e-33\n",
      "  1.00824229e-01 -6.87213317e-02 -2.73276884e-02  6.15926124e-02\n",
      "  3.18097137e-03  8.00507814e-02 -3.12689692e-02  8.40225816e-03\n",
      " -2.34864056e-02  2.17971019e-02  6.15382046e-02 -1.26555320e-02\n",
      "  7.85425752e-02 -4.38612439e-02  4.26587760e-02  2.70734094e-02\n",
      "  9.46157798e-02 -3.63097079e-02 -3.23266871e-02  2.29669102e-02\n",
      "  9.08504650e-02  1.09991558e-01 -5.77059537e-02 -6.45471886e-02\n",
      " -5.35795577e-02  2.39740741e-02  1.97971426e-02 -6.68076109e-06\n",
      " -4.70125340e-02  8.41596127e-02 -3.90419625e-02 -6.81605935e-02\n",
      "  1.34864114e-02 -2.58826762e-02  3.21369735e-03 -1.02614373e-01\n",
      " -1.86739080e-02  1.37878563e-02  2.55409768e-03  7.75613543e-03\n",
      "  1.91468783e-02 -9.00536850e-02 -1.06502613e-02  1.13201432e-01\n",
      "  9.58024189e-02 -9.87388268e-02 -1.48038849e-01 -1.34264911e-02\n",
      "  1.69807702e-01 -2.05428433e-02  3.80748697e-02 -5.10626584e-02\n",
      "  3.02968044e-02 -7.61739984e-02  6.89175073e-03 -3.02055329e-02\n",
      " -4.53071594e-02 -4.16841730e-02  7.99071491e-02  8.56502131e-02\n",
      "  2.94681583e-02  9.29997042e-02  8.81462637e-03 -1.19467126e-02\n",
      " -2.13473495e-02  6.11680970e-02  1.31520759e-02 -4.97700050e-02\n",
      " -2.39779223e-02  5.50015941e-02  2.85448674e-02 -3.17870267e-02\n",
      " -2.48832814e-02  3.49438167e-04  4.43246737e-02  3.60549730e-03\n",
      "  8.12435076e-02  4.26082779e-03  3.68464924e-02  4.51426916e-02\n",
      "  4.86307591e-03 -4.21461575e-02  1.29243642e-01 -2.78439224e-02\n",
      "  7.99208786e-03  9.68870707e-03 -1.53783727e-02  5.76755479e-02\n",
      " -7.39060491e-02  5.22860698e-03 -7.56507441e-02 -1.29122345e-03\n",
      " -2.96517815e-02  2.06811298e-02  2.98410617e-02 -6.02400547e-08\n",
      " -8.90068710e-03 -1.72451437e-02 -3.75160873e-02 -4.68034856e-02\n",
      " -2.83739362e-02 -6.16912283e-02  4.13605347e-02 -1.09645426e-02\n",
      " -2.35729553e-02  5.87733695e-03  8.80184695e-02 -5.73812053e-02\n",
      " -4.17495193e-03  4.59750108e-02  2.54061241e-02  1.45986397e-03\n",
      " -2.19865628e-02  1.23539388e-01 -3.45965959e-02 -7.40928575e-02\n",
      "  9.17854458e-02 -1.31401382e-02  1.04604699e-01 -8.98498073e-02\n",
      "  1.09049575e-02 -2.79806852e-02 -3.62462625e-02 -6.75666146e-03\n",
      " -2.02112878e-03  1.64064430e-02  1.24885686e-01  3.32908845e-03\n",
      "  8.66441578e-02 -1.49203530e-02  3.05642691e-02 -6.39267918e-03\n",
      " -8.76619369e-02 -3.79580744e-02  5.01525477e-02 -4.31967117e-02\n",
      " -5.93241081e-02 -9.33367983e-02 -7.81310424e-02 -4.77891378e-02\n",
      "  9.09752473e-02 -1.72796529e-02 -6.91601709e-02  4.33542812e-03\n",
      " -1.17292188e-01  6.39348030e-02  6.41631857e-02 -4.31126915e-02\n",
      "  3.16552445e-02  5.12911864e-02 -1.11293290e-02  3.46525051e-02\n",
      " -3.82546857e-02 -1.98401939e-02  1.51008284e-02  8.45859479e-03\n",
      "  8.79738852e-02 -7.80623332e-02 -9.08572450e-02 -2.51416732e-02]\n",
      "\n",
      "---\n",
      "\n",
      "Document ID: 4bc6ceab-56d1-4fc9-af07-10672bbdf9b6\n",
      "document_content: page_content='\"LVR-3001\": \"Convertible sofa bed upholstered in navy blue linen fabric, easily transitions from sofa to full-size sleeper. Perfect for guests or small living spaces. Features a sturdy wooden frame. Produced by SofaBed Solutions. Dimensions: 70\\\"W x 38\\\"D x 35\\\"H.\",\n",
      "  \"LVR-3002\": \"Ornate Persian area rug in deep red and gold, hand-knotted from silk and wool. Adds a luxurious touch to any living room. Measures 8' x 10'. Manufactured by Ancient Weaves.\",\n",
      "  \"LVR-3003\": \"Contemporary TV stand in matte black with tempered glass doors and chrome legs. Features integrated cable management and adjustable shelves. Accommodates up to 65-inch TVs. Made by Streamline Tech. Dimensions: 60\\\"W x 20\\\"D x 24\\\"H.\",' metadata={'file_name': 'test_data'}\n",
      "Metadata: {'file_name': 'test_data'}\n",
      "Vector: [-3.99023015e-03 -7.69299865e-02 -2.14933753e-02 -6.35428801e-02\n",
      "  2.77992077e-02  7.59174600e-02 -2.80265696e-02  2.46682558e-02\n",
      " -1.66442581e-02  7.85839409e-02 -5.75745553e-02  1.55313006e-02\n",
      "  3.68537977e-02  2.76860110e-02 -7.69242272e-02 -2.72752787e-03\n",
      "  3.68818338e-03 -8.19364786e-02  1.14564626e-02  7.87074268e-02\n",
      " -3.39150056e-02  2.48903688e-02  4.65518469e-03 -1.28780305e-02\n",
      "  1.72110461e-02 -4.72744182e-02 -2.10658368e-02 -6.50285883e-03\n",
      "  3.13102826e-02 -1.89160276e-02  6.22201487e-02 -9.09314863e-03\n",
      "  5.08615598e-02  3.71281877e-02 -3.27224508e-02 -2.48730481e-02\n",
      " -2.40327455e-02 -4.70427722e-02 -9.02794302e-02  9.52196047e-02\n",
      " -5.29424660e-02 -2.94257496e-02 -2.50157202e-03  4.18597227e-03\n",
      "  1.25536304e-02 -1.23713817e-02 -2.11440492e-02 -3.91181260e-02\n",
      " -2.37141736e-02 -3.06449328e-02 -4.19731028e-02 -1.89957451e-02\n",
      " -2.47054081e-02  4.49278206e-02 -7.53065720e-02 -1.69451553e-02\n",
      " -2.43933816e-02  7.86893815e-02  4.59521078e-02 -5.87263852e-02\n",
      "  7.96881914e-02  2.76885182e-02  5.87469116e-02 -1.28005557e-02\n",
      "  5.79060614e-03  5.89583404e-02 -6.34446144e-02  2.25242972e-02\n",
      "  2.04331856e-02  8.49595387e-03 -1.29471838e-01  2.67081782e-02\n",
      " -1.67868994e-02  6.90010116e-02  1.42127918e-02 -6.10003136e-02\n",
      "  5.89867905e-02 -4.79003862e-02  4.48905677e-02  3.78422700e-02\n",
      " -5.93374819e-02  1.96955279e-02 -1.67389467e-01  5.55860028e-02\n",
      " -5.31341434e-02 -3.99562949e-03  2.07266286e-02  5.00663742e-02\n",
      " -2.54123826e-02 -6.12918846e-02 -9.58537683e-03  2.72984616e-02\n",
      " -4.34136949e-02  2.52155308e-02 -3.36839780e-02  8.40275437e-02\n",
      " -2.28489451e-02 -3.47042866e-02  6.37545064e-02  2.70651504e-02\n",
      "  6.20222976e-03  8.76486488e-03  7.86778778e-02  5.71473502e-03\n",
      " -9.28206518e-02 -7.79720247e-02  5.36941811e-02  4.16289642e-02\n",
      " -3.10524683e-02 -6.49636537e-02 -4.10733558e-02  6.49232278e-03\n",
      " -4.33000363e-02 -6.45373133e-04  3.68175544e-02 -1.91493426e-02\n",
      "  1.20861428e-02  3.23962718e-02  1.21086404e-01 -7.67311826e-02\n",
      "  1.35982141e-01 -1.07627837e-02  4.00140882e-02 -3.00952327e-02\n",
      " -5.18528447e-02 -1.52291730e-02  4.64438088e-02  3.10015954e-33\n",
      "  4.98807896e-03  6.73817322e-02 -5.04543781e-02  9.67028290e-02\n",
      "  3.78761180e-02  6.48467317e-02  2.63834670e-02  1.33620888e-01\n",
      " -2.68822983e-02  6.66090026e-02  5.22125997e-02 -3.66717912e-02\n",
      " -3.46571184e-03  5.00392355e-02  3.73762101e-02 -3.24989296e-02\n",
      " -3.52567062e-02 -8.48450325e-03 -5.78717813e-02  1.00017674e-02\n",
      " -4.11656164e-02  5.86594082e-02  9.39245895e-02  3.89772244e-02\n",
      " -3.04122362e-03 -4.85845543e-02  3.22399139e-02 -2.18642149e-02\n",
      " -8.12233239e-02 -1.37528153e-02  4.35136519e-02 -4.00356464e-02\n",
      "  1.01932380e-02  1.67768006e-03 -8.40537101e-02 -6.57854304e-02\n",
      " -7.09081665e-02 -4.54748124e-02 -3.13873286e-03  6.54730424e-02\n",
      "  8.90217256e-03  7.23920241e-02 -8.91989004e-03  7.27597252e-02\n",
      " -1.67135336e-03  8.44567642e-02  8.24481770e-02  5.88597870e-03\n",
      " -1.02711758e-02 -1.76217426e-02 -6.41487353e-03  4.01501730e-02\n",
      " -6.38398975e-02 -1.20882422e-01 -2.66538914e-02 -3.05604078e-02\n",
      " -4.22377698e-02 -4.50905785e-03  4.70544137e-02 -2.75119790e-03\n",
      "  4.69285809e-02  2.98609268e-02  8.74149799e-02  2.96716448e-02\n",
      " -4.39369082e-02 -7.71264210e-02  8.89412314e-02 -2.04419461e-03\n",
      "  3.38527337e-02 -3.54277566e-02 -6.05436191e-02 -3.88147458e-02\n",
      "  2.97210291e-02 -6.72347993e-02  6.12355443e-03  1.43449788e-03\n",
      " -6.56761900e-02 -2.28395518e-02 -2.35994719e-02 -7.60842636e-02\n",
      " -1.13104790e-01  1.85343958e-02  6.99155182e-02  2.75970735e-02\n",
      " -1.03148185e-02 -4.98087406e-02  2.02440880e-02 -6.65221438e-02\n",
      " -7.76382685e-02 -8.83092135e-02  5.69220912e-03 -3.14906575e-02\n",
      "  6.81196079e-02 -5.05793020e-02  1.88019089e-02 -4.49101694e-33\n",
      "  9.22726095e-02 -3.97208966e-02 -8.16312060e-02 -8.26278627e-02\n",
      "  7.32439617e-03 -2.20365226e-02  1.34107582e-02  4.67417203e-02\n",
      " -1.11816749e-02  1.30048208e-02  5.11089079e-02 -6.73130825e-02\n",
      "  1.81063209e-02 -2.62236465e-02  1.83963254e-02  4.35330085e-02\n",
      "  8.50064531e-02 -8.08362514e-02  1.41077675e-04 -5.51311225e-02\n",
      "  1.13783978e-01  4.20396868e-03 -3.74429561e-02  3.37402523e-02\n",
      " -3.08662821e-02 -1.43755805e-02  2.99833678e-02 -2.95329513e-03\n",
      " -3.01564168e-02  7.63781508e-03 -6.88543096e-02 -9.88967419e-02\n",
      " -2.03111442e-03  6.77106157e-02  1.04356548e-02 -2.06484012e-02\n",
      "  5.30763455e-02 -3.82671095e-02  5.67826070e-03 -4.02556881e-02\n",
      "  9.65566859e-02 -1.85467992e-02 -4.37028855e-02 -2.67600622e-02\n",
      "  1.17462396e-03 -5.79201020e-02 -5.63825816e-02 -3.10094096e-02\n",
      "  6.17411174e-02 -4.64324504e-02  4.97123227e-02 -1.15381358e-02\n",
      "  6.33349195e-02 -1.33766951e-02  3.75348516e-02 -2.64841947e-04\n",
      " -4.16584313e-02  3.15669551e-02  5.85102551e-02  7.89485201e-02\n",
      "  3.56176011e-02  5.22136427e-02 -5.27182110e-02  1.81307718e-02\n",
      " -4.83568478e-03  7.01461062e-02  3.15703861e-02 -5.38867675e-02\n",
      " -4.41726521e-02 -2.04859301e-02  1.04239680e-01 -4.49240394e-02\n",
      " -2.86356267e-02  2.27612276e-02 -7.17397928e-02 -2.40670554e-02\n",
      "  9.25325900e-02 -3.56484763e-02  5.66909127e-02  6.42299131e-02\n",
      "  2.64089070e-02 -4.82695140e-02  3.29297669e-02  8.49465653e-03\n",
      "  5.58664501e-02 -6.40481664e-03 -5.87600842e-02  9.16865170e-02\n",
      "  4.91155013e-02  2.14273036e-02 -2.56680809e-02  7.62494355e-02\n",
      " -9.87187847e-02 -2.09088288e-02  1.07382081e-01 -4.73674433e-08\n",
      " -3.77490483e-02 -9.89983696e-03 -6.14240021e-02 -7.75386067e-03\n",
      " -3.68668362e-02 -1.03823796e-01  8.56785327e-02 -2.59601325e-02\n",
      "  2.32109800e-03 -6.67505264e-02  3.55934538e-02 -1.06862471e-01\n",
      "  2.92835627e-02  3.73061039e-02  6.43269718e-02 -6.86285365e-03\n",
      " -1.21362358e-01  1.22974060e-01 -4.35346738e-02  3.12695764e-02\n",
      "  5.83505370e-02 -2.42142230e-02  3.02101225e-02 -2.25081686e-02\n",
      " -3.12088374e-02 -1.00876968e-02 -5.11207245e-02 -1.73838474e-02\n",
      "  8.01993683e-02 -2.19951104e-02  2.11147834e-02  1.46342590e-02\n",
      "  2.91671529e-02 -7.49628618e-02  3.43204220e-03  3.85126583e-02\n",
      " -4.43427227e-02 -6.76257163e-02 -8.47251900e-03 -4.16476652e-02\n",
      "  1.39376745e-02 -1.24961913e-01 -2.80638654e-02 -3.04966029e-02\n",
      "  9.19755846e-02 -3.13230790e-02 -4.20511514e-02 -8.59244727e-03\n",
      " -1.68008450e-03  7.34358057e-02  3.69167104e-02  7.87878595e-03\n",
      "  7.85665214e-03  2.72758119e-02 -1.67591032e-02 -3.85719128e-02\n",
      " -1.24519579e-02  6.54379651e-02  4.71435152e-02 -6.80986345e-02\n",
      "  1.88399106e-02  5.47381956e-03  5.38075855e-03  5.59832938e-02]\n",
      "\n",
      "---\n",
      "\n",
      "Document ID: 7dd5c830-cc82-46f8-875c-469de2041e1a\n",
      "document_content: page_content='\"OPT-4001\": \"Modular outdoor sofa set in espresso brown polyethylene wicker, includes three corner pieces and two armless chairs with water-resistant cushions in cream. Configurable to fit any patio space. Produced by Outdoor Living. Corner dimensions: 32\\\"W x 32\\\"D x 28\\\"H, Armless dimensions: 28\\\"W x 32\\\"D x 28\\\"H.\",\n",
      "  \"OPT-4002\": \"Cantilever umbrella in sunflower yellow, featuring a 10-foot canopy and adjustable tilt for optimal shade. Constructed with a sturdy aluminum pole and fade-resistant fabric. Manufactured by Shade Masters. Dimensions: 120\\\"W x 120\\\"D x 96\\\"H.\",\n",
      "  \"OPT-4003\": \"Rustic fire pit table made from faux stone, includes a natural gas hookup and a matching cover. Ideal for evening gatherings on the patio. Manufactured by Warmth Outdoor. Dimensions: 42\\\"W x 42\\\"D x 24\\\"H.\",' metadata={'file_name': 'test_data'}\n",
      "Metadata: {'file_name': 'test_data'}\n",
      "Vector: [ 6.25239387e-02  6.14061169e-02 -2.60913819e-02  3.46072428e-02\n",
      "  5.85005768e-02 -1.87208988e-02  7.41202682e-02 -3.29577848e-02\n",
      "  2.78308336e-03  5.52778430e-02 -9.40392092e-02 -3.49877514e-02\n",
      "  1.30265774e-02 -9.44245316e-04  2.06332356e-02  4.58725877e-02\n",
      "  5.51217748e-03 -5.91669679e-02  3.12608369e-02  7.10940659e-02\n",
      " -1.16097525e-01 -5.57903685e-02  3.39469337e-03 -3.74610834e-02\n",
      " -7.71723390e-02  2.11889129e-02 -5.61592616e-02  6.55304417e-02\n",
      " -5.17867273e-04 -1.02986218e-02  1.10310450e-01  2.83263419e-02\n",
      " -3.25478315e-02  6.04225546e-02  1.20900590e-02 -3.90942097e-02\n",
      " -3.32924933e-03 -3.91788445e-02 -4.87329252e-02  1.13369793e-01\n",
      " -5.49739376e-02 -2.32229605e-02 -3.15156616e-02  1.28614772e-02\n",
      " -6.36051744e-02  9.19209514e-03 -7.81456158e-02 -4.12136829e-03\n",
      " -3.85773219e-02 -2.81760842e-02 -6.71660947e-03  7.20082084e-03\n",
      " -9.08900518e-03 -6.80483133e-02  1.85601003e-02 -1.01397876e-02\n",
      "  3.01754959e-02  5.87948672e-02  2.13534441e-02 -3.81117314e-02\n",
      "  6.04829304e-02 -3.93454805e-02  1.12344334e-02 -3.68949026e-02\n",
      "  2.24958305e-04  6.40539303e-02 -8.21505338e-02 -3.32826674e-02\n",
      " -1.88911762e-02 -3.12291402e-02 -4.74821739e-02  8.20548236e-02\n",
      "  2.82132886e-02 -5.74310012e-02 -4.03793603e-02 -5.00346385e-02\n",
      "  5.13014644e-02 -2.62314151e-03  1.85961602e-03  5.77952303e-02\n",
      " -5.07560819e-02  9.10662115e-02 -1.87653303e-02  3.33754569e-02\n",
      " -5.66242188e-02 -3.46974446e-03 -1.40597383e-02  7.50401691e-02\n",
      " -7.85769746e-02 -2.93061547e-02 -3.92352194e-02  2.80717527e-03\n",
      " -5.59441820e-02  9.78629570e-03 -4.44232933e-02  7.92999193e-02\n",
      "  3.66924815e-02 -6.15987331e-02 -1.50969401e-02  6.75879568e-02\n",
      "  2.92261131e-04  1.22239273e-02 -1.78973954e-02  5.56450710e-03\n",
      " -1.08394794e-01 -9.35126990e-02 -1.10295424e-02  2.14995183e-02\n",
      "  3.91389653e-02 -3.73674110e-02 -5.94031848e-02 -5.69341779e-02\n",
      " -1.46145932e-03 -6.34523993e-03 -8.56982768e-02 -2.39622090e-02\n",
      "  3.88854668e-02 -3.73176821e-02  8.57335255e-02 -6.40118197e-02\n",
      "  6.49238750e-02  9.83056352e-02  6.30926192e-02  8.67246762e-02\n",
      " -2.60672309e-02  4.39220108e-02  1.47211272e-02  3.51855802e-33\n",
      "  1.78124085e-02  7.71324337e-02  6.41972572e-02  2.09520161e-02\n",
      "  1.46197394e-01 -3.66482362e-02  4.75722328e-02  5.38918041e-02\n",
      "  4.29277867e-03  2.29640361e-02  3.29253823e-02 -2.78491676e-02\n",
      "  2.28955466e-02 -3.38062528e-04  9.07923877e-02 -3.26957740e-02\n",
      "  1.14403870e-02  2.84539871e-02 -5.23915775e-02 -2.32286062e-02\n",
      " -1.00893572e-01 -1.76771022e-02  7.35675022e-02  4.32922319e-02\n",
      " -2.33191578e-03  4.76135574e-02  3.88897136e-02  1.69114806e-02\n",
      " -3.28801200e-02 -6.05566008e-03  4.74391654e-02 -8.80156457e-02\n",
      "  3.05153988e-02  6.74873963e-02 -4.49304767e-02 -9.27193314e-02\n",
      " -5.65782115e-02  1.65207814e-02  3.44714820e-02 -5.07824272e-02\n",
      " -4.76501398e-02  3.15561406e-02  8.85296240e-02  6.31544814e-02\n",
      " -2.85362881e-02 -1.28540797e-02  9.29319263e-02 -9.10098723e-04\n",
      " -1.56554412e-02 -7.05361888e-02 -3.55128385e-02  1.05953194e-01\n",
      " -9.19868704e-03 -3.45788598e-02 -4.63522449e-02 -4.78344001e-02\n",
      "  1.13079650e-02  7.98519060e-04 -2.82581616e-03  2.33017886e-03\n",
      "  6.38714731e-02  7.98960216e-03  5.15635824e-03 -9.16809812e-02\n",
      " -1.34599013e-02 -3.60052958e-02 -2.09653713e-02 -3.40701975e-02\n",
      "  4.95164879e-02 -5.62009625e-02  9.45044309e-03  2.50319000e-02\n",
      "  9.65171605e-02 -1.43766999e-02 -2.30332371e-02  4.95680980e-02\n",
      "  3.07165701e-02 -3.42912339e-02 -2.35593598e-02  1.90249477e-02\n",
      " -3.79807316e-02  5.74698076e-02  3.85309160e-02 -6.17891513e-02\n",
      " -9.84642059e-02 -1.41565263e-01  4.38057333e-02  7.89320678e-04\n",
      " -6.37843832e-02 -3.56441773e-02 -4.18437161e-02 -4.01517712e-02\n",
      "  7.56760174e-03 -5.37478365e-02 -2.18474045e-02 -5.25138987e-33\n",
      "  2.69480757e-02 -1.30256973e-02 -1.01221941e-01 -1.10181101e-01\n",
      "  4.87016328e-02  1.17044048e-02 -5.85603379e-02 -3.25369276e-02\n",
      " -6.23098388e-02  1.51211061e-02 -3.19586769e-02  5.52461948e-03\n",
      "  6.83384165e-02 -1.52224284e-02 -6.85668364e-02  4.90138978e-02\n",
      " -1.47753814e-02 -7.72373611e-03 -4.60414737e-02 -1.00945279e-01\n",
      "  6.06268384e-02  9.13792476e-02  4.75758978e-04  6.44441023e-02\n",
      " -6.41274974e-02  1.51737379e-02  9.25551653e-02 -7.06992596e-02\n",
      " -3.00319027e-02  4.22831066e-02 -6.87024519e-02 -6.23287931e-02\n",
      " -1.94077846e-02  5.15124872e-02  4.75017503e-02 -9.42867249e-02\n",
      " -2.77982950e-02 -1.44195165e-02 -1.87980365e-02 -1.87711138e-02\n",
      "  4.15471159e-02 -1.48415267e-02  4.37392890e-02 -2.24025478e-03\n",
      "  3.89449596e-02 -6.13630265e-02 -5.78924604e-02 -4.33812756e-03\n",
      "  5.78073226e-02 -4.35646139e-02  3.95364081e-03  2.15157308e-02\n",
      " -3.22814360e-02  2.18701623e-02  4.34273444e-02 -1.09193608e-01\n",
      " -4.90869097e-02 -8.03508237e-03 -2.28017904e-02  3.04047558e-02\n",
      " -2.03988026e-03  7.08683506e-02  1.38242720e-02  1.09770186e-01\n",
      "  1.34277530e-02  6.68969676e-02 -6.70412704e-02 -8.23089629e-02\n",
      " -2.12518387e-02  4.14168090e-02 -4.71605500e-03  1.15616648e-02\n",
      " -6.09698258e-02  5.12588322e-02  2.44606589e-03  2.60084644e-02\n",
      "  1.28483877e-01  8.56635273e-02  3.03645339e-02  7.31901005e-02\n",
      "  3.60937696e-03  3.16695496e-02  2.15495247e-02  1.28463181e-02\n",
      "  8.21349695e-02 -7.06039593e-02 -2.47733053e-02  6.52337372e-02\n",
      " -5.46203852e-02  4.71003950e-02 -3.50368023e-02  9.01784003e-02\n",
      " -7.59689957e-02  5.86871020e-02  2.91845426e-02 -5.52877211e-08\n",
      " -7.72388354e-02 -4.79667261e-02 -2.31845640e-02  2.31585815e-03\n",
      " -2.70408038e-02 -1.11464754e-01  1.09817125e-01 -7.71314427e-02\n",
      " -4.74677235e-02 -9.11741704e-02 -1.45375757e-02 -5.20413592e-02\n",
      "  4.29490209e-02  6.11630604e-02 -2.29965150e-02 -2.39292085e-02\n",
      "  1.14901469e-03  6.50247708e-02 -8.59468710e-03  1.87819786e-02\n",
      "  4.37338231e-03 -6.31784275e-02 -1.98956449e-02  1.85459002e-03\n",
      " -5.75988702e-02 -8.51170253e-03 -3.93241905e-02 -3.40596586e-02\n",
      "  8.81838948e-02  8.53007063e-02  2.98095942e-02 -1.55830514e-02\n",
      " -9.51657165e-03 -2.36424021e-02 -7.62203103e-03  3.82097065e-02\n",
      " -5.23337685e-02 -1.83624160e-02 -6.92881420e-02  3.03893704e-02\n",
      " -1.40378289e-02 -1.23202251e-02 -5.79818301e-02 -1.60205252e-02\n",
      "  9.17090476e-02  1.81509983e-02 -8.14809576e-02  1.81536358e-02\n",
      " -2.39259191e-02  6.07863553e-02  4.59668711e-02 -3.17111947e-02\n",
      "  4.96709235e-02  3.94596979e-02  8.29051062e-03  1.68697201e-02\n",
      " -3.09716240e-02  2.38592327e-02  9.15950239e-02  3.08318762e-03\n",
      "  8.27155709e-02  2.05979515e-02 -3.41761000e-02  6.13344237e-02]\n",
      "\n",
      "---\n",
      "\n",
      "Document ID: 134dcfe9-9aa2-4abd-bd03-ea98842df332\n",
      "document_content: page_content='\"ENT-5001\": \"Digital jukebox with touchscreen interface and built-in speakers, capable of streaming music and playing CDs. Retro design with modern technology, includes customizable LED lighting. Produced by RetroSound. Dimensions: 24\\\"W x 15\\\"D x 48\\\"H.\",\n",
      "  \"ENT-5002\": \"Gaming console storage unit in sleek black, featuring designated compartments for systems, controllers, and games. Ventilated to prevent overheating. Manufactured by GameHub. Dimensions: 42\\\"W x 16\\\"D x 24\\\"H.\",\n",
      "  \"ENT-5003\": \"Virtual reality gaming set by VR Innovations, includes headset, two motion controllers, and a charging station. Offers a comprehensive library of immersive games and experiences.\",' metadata={'file_name': 'test_data'}\n",
      "Metadata: {'file_name': 'test_data'}\n",
      "Vector: [-1.54415471e-02  5.29988073e-02  2.09478661e-02 -9.75871235e-02\n",
      "  5.36338333e-03 -1.29506234e-02  3.61018516e-02  8.30856115e-02\n",
      " -2.52572875e-02  4.66403626e-02 -8.69382732e-03 -4.34608348e-02\n",
      "  1.55575629e-02 -9.76881459e-02  4.82430216e-03 -1.09597379e-02\n",
      "  1.03446692e-01 -1.48656052e-02  6.39286488e-02 -1.29697751e-02\n",
      " -2.34572291e-02 -3.90263759e-02  1.15013858e-02 -3.23177725e-02\n",
      " -5.10697998e-02  1.57278832e-02  1.10419430e-02  5.30131869e-02\n",
      " -9.47720855e-02 -7.42397457e-02 -5.80396922e-03  2.51937546e-02\n",
      " -5.45006357e-02 -1.75420614e-03 -4.29328484e-03 -1.83718279e-02\n",
      "  6.83915475e-03 -5.86878583e-02 -5.01531847e-02 -1.14208110e-01\n",
      " -5.36696054e-02  8.74736067e-03 -1.86487306e-02  7.25902021e-02\n",
      "  3.59827168e-02  8.15996900e-03 -7.82647952e-02 -8.20572674e-02\n",
      " -2.20865905e-02 -1.22763915e-02  6.50169700e-02 -2.81989593e-02\n",
      "  6.51471242e-02  4.17294092e-02  2.02578977e-02  3.12183681e-03\n",
      " -5.99111803e-02  4.91994359e-02  2.34297216e-02 -2.26855334e-02\n",
      "  1.15560167e-01 -2.70245764e-02 -1.56968907e-02 -3.55225615e-02\n",
      "  8.88383295e-03 -4.61944286e-03  2.28757616e-02 -2.76237540e-02\n",
      " -3.09727527e-02 -8.06305408e-02 -6.75323159e-02  1.08034788e-02\n",
      " -4.52733636e-02  8.11769441e-03 -4.23437692e-02  1.08636392e-03\n",
      " -2.50728847e-03 -2.26317495e-02 -4.21086103e-02  8.81803036e-02\n",
      "  6.65904433e-02  5.54587469e-02 -5.30440100e-02  9.71888890e-04\n",
      " -1.13549642e-02  3.45823839e-02 -1.04554892e-02  6.08580261e-02\n",
      " -6.36297762e-02 -4.93651368e-02 -9.69227478e-02 -7.50981644e-02\n",
      "  2.10266393e-02  5.38646476e-03 -3.27733196e-02  7.96881970e-03\n",
      " -4.93099242e-02 -6.01649359e-02 -3.03425528e-02  3.77927348e-02\n",
      "  7.36957602e-03  3.45729440e-02  9.92540568e-02  1.53921628e-02\n",
      "  3.49296294e-02 -5.09139337e-02  4.23461609e-02  9.02340561e-02\n",
      "  1.90150477e-02 -3.68407927e-02 -1.12358868e-01 -1.13598131e-01\n",
      " -5.17853238e-02 -1.23835597e-02  5.30905835e-02  1.07334005e-02\n",
      " -3.56546082e-02  1.17039397e-01  7.64453709e-02 -6.15950264e-02\n",
      "  1.36804283e-01  3.25635634e-02  1.05647417e-02 -9.42456536e-03\n",
      " -2.11678017e-02 -1.16688479e-02  1.59578724e-03  2.17001069e-33\n",
      "  2.34589521e-02  8.68631899e-03  3.28903198e-02  8.86363387e-02\n",
      "  5.02291182e-03  6.82547465e-02  6.90585971e-02  6.22649156e-02\n",
      " -1.14537673e-02  1.46697136e-03 -2.67082807e-02  7.12897722e-03\n",
      " -3.06304377e-02  1.56359538e-01  5.95596395e-02 -8.35672468e-02\n",
      " -7.64991939e-02  3.94391753e-02 -1.63274426e-02 -5.46443015e-02\n",
      " -6.05304316e-02  2.44929697e-02  3.44278626e-02 -7.49223912e-03\n",
      "  7.45488738e-04  1.09836292e-02 -2.44913977e-02 -2.79866308e-02\n",
      "  5.06100431e-02  1.02118598e-02 -1.98044684e-02  2.38747448e-02\n",
      " -1.10147782e-02 -5.27107529e-02  1.42772449e-02  9.00231302e-03\n",
      "  5.02895303e-02 -2.94634774e-02  1.54464657e-03 -1.40862335e-02\n",
      "  5.40469657e-04  7.38078803e-02 -5.06640971e-02 -3.33828516e-02\n",
      " -3.10191847e-02  3.66658755e-02  4.84133884e-02 -3.34399045e-02\n",
      "  7.76773766e-02  1.59623288e-02 -1.24636963e-01  1.89641211e-02\n",
      " -4.07420211e-02 -6.75728768e-02  3.37623954e-02 -4.79846448e-02\n",
      "  7.28040561e-02  5.74034452e-02  2.76254509e-02  8.19617361e-02\n",
      " -9.73738451e-03  1.49415908e-02  3.84754688e-02 -3.24090421e-02\n",
      " -7.61879385e-02  7.54179806e-02  2.19030771e-02 -6.26505092e-02\n",
      " -2.20841132e-02 -6.39619725e-03 -4.46217246e-02 -4.69655637e-03\n",
      "  8.06064233e-02 -1.34790717e-02  2.15163678e-02  3.08181345e-02\n",
      " -6.24139309e-02 -1.29608838e-02 -1.33392140e-01  1.34159634e-02\n",
      " -5.24976216e-02 -5.75045496e-02 -6.48247600e-02  9.94590949e-03\n",
      "  6.24212474e-02 -5.71087003e-02  4.35946882e-03 -2.54272595e-02\n",
      " -2.45648082e-02 -3.98623236e-02 -2.70614736e-02  3.19166258e-02\n",
      " -1.67796426e-02  2.49993671e-02 -5.26950359e-02 -3.59232433e-33\n",
      "  2.97160894e-02 -1.50022749e-02 -5.62385842e-02 -1.20723993e-02\n",
      "  2.69122291e-02  2.49708612e-02 -3.93851921e-02  1.04573056e-01\n",
      "  8.87738448e-03  7.28768036e-02  2.54900847e-02 -3.28961969e-03\n",
      "  6.32678643e-02  1.39109613e-02 -4.23023524e-03  2.06312221e-02\n",
      " -4.41272231e-03 -9.80485827e-02  2.40376871e-02 -2.21068095e-02\n",
      "  3.64142284e-02  6.73612058e-02 -3.22046783e-03 -6.51481608e-03\n",
      "  2.05222480e-02  6.59066141e-02  4.23940085e-02 -3.87484953e-02\n",
      " -4.75600809e-02 -1.19884149e-03 -6.32576048e-02 -6.83178753e-02\n",
      "  5.04257232e-02  9.65367556e-02 -1.44835305e-03 -1.34637719e-02\n",
      "  1.01362832e-01 -4.04213741e-02 -1.28469065e-01 -4.33217920e-02\n",
      "  1.81387402e-02  2.60786079e-02 -3.96688655e-02  5.38304336e-02\n",
      "  1.33168036e-02 -2.39659734e-02 -5.55431917e-02 -3.44371386e-02\n",
      "  9.25976560e-02  2.40432424e-03  5.46503998e-02 -4.14011516e-02\n",
      "  4.28964905e-02 -2.52378099e-02 -1.89868826e-02 -9.24601406e-02\n",
      " -2.97152530e-02  8.31773058e-02  1.31633263e-02  2.67073046e-02\n",
      "  1.10075392e-01  7.09163472e-02 -1.90200750e-02 -3.50558832e-02\n",
      " -1.62876640e-02 -1.16124470e-02  7.39217782e-03 -6.97431434e-03\n",
      " -2.75354907e-02 -7.38822520e-02 -3.40389524e-04 -4.84421700e-02\n",
      " -4.49696602e-03 -3.01826485e-02 -2.86279470e-02 -9.76181403e-03\n",
      "  1.48758246e-03 -2.83583961e-02  5.21228537e-02  1.90147627e-02\n",
      " -4.02523950e-02  2.87628197e-03  5.99352047e-02  3.28096710e-02\n",
      "  4.21997793e-02 -2.80608609e-03 -2.84554437e-02  4.82293703e-02\n",
      " -4.47147377e-02  4.39244742e-03 -3.72081473e-02  1.01513445e-01\n",
      " -6.52518421e-02  1.68483362e-01  2.42406204e-02 -5.11884473e-08\n",
      "  2.59888787e-02 -4.15047109e-02 -4.94852811e-02  1.06307035e-02\n",
      " -7.81308264e-02 -8.52551535e-02  1.02873445e-01  8.25202279e-03\n",
      "  3.97623628e-02 -4.17781658e-02  5.00460044e-02 -3.55385318e-02\n",
      " -6.38412312e-03  9.25124735e-02  8.55070725e-02  3.49571668e-02\n",
      " -9.04839635e-02  1.16402179e-01 -3.71762477e-02  5.44178560e-02\n",
      "  7.28172902e-03  1.35782119e-02  8.77796412e-02 -8.31167027e-02\n",
      " -2.15801857e-02  1.86383668e-02 -4.57413048e-02 -2.02598628e-02\n",
      "  7.24608526e-02  3.57999392e-02  2.56917384e-02 -2.10101400e-02\n",
      "  1.51231298e-02 -8.59828815e-02 -7.08422437e-02 -1.12758372e-02\n",
      " -9.25841630e-02  5.03964862e-03  3.51631679e-02  4.24645171e-02\n",
      " -2.21715905e-02 -1.19950540e-01 -9.52846557e-02  6.85028220e-03\n",
      "  2.58876327e-02 -5.02206534e-02 -3.11267246e-02 -4.99435104e-02\n",
      " -8.40942115e-02  1.13752382e-02 -5.42763434e-02  2.39363313e-02\n",
      "  1.17882723e-02 -1.57842394e-02  2.59351190e-02  4.65138927e-02\n",
      " -1.58625208e-02  5.91724515e-02  5.18701524e-02  1.37488302e-02\n",
      "  5.25571555e-02  5.63284289e-03 -1.15921106e-02  1.13506265e-01]\n",
      "\n",
      "---\n",
      "\n",
      "Document ID: 16848d3a-d71d-4558-a787-818182bf15eb\n",
      "document_content: page_content='\"KIT-6001\": \"Chef's rolling kitchen cart in stainless steel, features two shelves, a drawer, and towel bars. Portable and versatile, ideal for extra storage and workspace in the kitchen. Produced by KitchenAid. Dimensions: 30\\\"W x 18\\\"D x 36\\\"H.\",\n",
      "  \"KIT-6002\": \"Contemporary pendant light cluster with three frosted glass shades, suspended from a polished nickel ceiling plate. Provides elegant, diffuse lighting over kitchen islands. Manufactured by Luminary Designs. Adjustable drop length up to 60\\\".\",\n",
      "  \"KIT-6003\": \"Eight-piece ceramic dinnerware set in ocean blue, includes dinner plates, salad plates, bowls, and mugs. Dishwasher and microwave safe, adds a pop of color to any meal. Produced by Tabletop Trends.\",' metadata={'file_name': 'test_data'}\n",
      "Metadata: {'file_name': 'test_data'}\n",
      "Vector: [-8.96942019e-02  1.47116063e-02 -3.51537541e-02 -2.62611378e-02\n",
      "  1.14705497e-02  6.10376475e-03 -2.26486586e-02  4.10903506e-02\n",
      " -2.98913643e-02 -8.93740281e-02 -2.45581660e-02 -1.00372337e-01\n",
      " -2.96978001e-02 -2.58225165e-02 -4.79869079e-03 -5.40561527e-02\n",
      "  1.72561109e-02 -1.57921873e-02 -2.64962092e-02 -2.08148044e-02\n",
      " -2.45205872e-02 -2.40246113e-03  8.06257427e-02 -2.18550023e-02\n",
      " -7.23049184e-03  5.52620403e-02  7.87176937e-02  4.53984812e-02\n",
      " -1.06160296e-02  1.87111516e-02  2.83769760e-02  1.16473980e-01\n",
      " -3.06487922e-02 -9.65722557e-03  2.46422645e-02 -3.40542048e-02\n",
      "  1.50203304e-02  1.88548081e-02  3.47997621e-03 -5.67447878e-02\n",
      " -1.81221440e-02 -1.32185137e-02  4.99218255e-02  1.04949325e-02\n",
      "  3.33061926e-02 -2.96064448e-02 -4.00180556e-03  2.74542030e-02\n",
      " -2.35222355e-02 -8.41838196e-02  1.72450095e-02 -1.70782879e-02\n",
      "  1.45046460e-02  5.32996505e-02  2.49445140e-02 -4.85454500e-03\n",
      " -6.72712177e-02 -6.22964539e-02  7.00061694e-02  2.09897477e-02\n",
      "  4.82738763e-02  1.48951178e-02 -1.47044258e-02 -9.68577061e-03\n",
      " -2.19885837e-02  5.84336668e-02 -3.82340550e-02 -9.78946779e-03\n",
      " -6.23318441e-02 -2.45876480e-02 -5.82803302e-02 -1.08760465e-02\n",
      "  8.92196596e-02  1.23056337e-01  5.20318076e-02 -8.08253977e-03\n",
      "  1.11735806e-01 -9.73337740e-02 -1.47895262e-01  2.25864667e-02\n",
      " -6.63136765e-02  3.80817130e-02 -6.58944100e-02  9.94021818e-02\n",
      " -7.05650672e-02  3.86373163e-03 -1.02293817e-02  4.97284345e-02\n",
      " -2.11015940e-02 -2.04739217e-02 -2.14047320e-02  3.28431055e-02\n",
      " -1.82005577e-02 -9.98970419e-02 -9.12674665e-02  8.21188018e-02\n",
      " -4.72107939e-02 -5.41002315e-04 -2.19267644e-02  5.40040992e-02\n",
      " -6.35263044e-03 -1.98992789e-02  4.53009568e-02  2.61801388e-02\n",
      "  2.38444936e-02  2.64377129e-04  4.39153872e-02  1.03296697e-01\n",
      "  4.66304347e-02 -2.49577723e-02 -1.52216312e-02 -2.58224420e-02\n",
      " -9.49659646e-02 -7.02317506e-02 -1.01252258e-01 -9.97879431e-02\n",
      "  1.44317513e-02  2.74526216e-02  7.80374333e-02  8.53528604e-02\n",
      "  1.06522441e-01  1.61015391e-02 -2.69724958e-04 -1.34440949e-02\n",
      " -4.44698073e-02 -6.39437046e-03  3.98001596e-02  1.71988378e-33\n",
      " -2.87838429e-02  1.44024231e-02  4.53624912e-02  5.20925000e-02\n",
      "  1.28394470e-01 -8.75703618e-02  6.12311549e-02  3.52241611e-03\n",
      " -1.35506717e-02 -1.71129908e-02  4.05065678e-02 -1.52165154e-02\n",
      " -8.99514109e-02  9.98225659e-02  6.98601305e-02 -6.49666712e-02\n",
      "  2.47325301e-02 -1.18774157e-02 -2.80187000e-02 -8.54958687e-03\n",
      " -5.48288450e-02 -4.37712446e-02  8.90309662e-02  5.05361073e-02\n",
      "  1.88361946e-02  5.65919243e-02  8.31603780e-02  4.06064950e-02\n",
      " -5.47253760e-03  5.38759260e-03  1.69890467e-02  7.90400580e-02\n",
      "  1.03988372e-01  7.66756060e-03 -7.39396513e-02  1.39715271e-02\n",
      " -5.80814853e-02 -4.66313288e-02  3.40503193e-02  3.07420222e-03\n",
      " -6.20636046e-02  6.87376186e-02  5.07254340e-03  1.11708999e-01\n",
      "  1.01836780e-02 -2.17319094e-03  3.09138242e-02  6.88942671e-02\n",
      "  5.91184162e-02  3.26052979e-02 -2.75878981e-02 -7.46194785e-03\n",
      "  4.34340686e-02  3.06465756e-02  3.12688574e-02 -2.75879782e-02\n",
      "  9.70861409e-03  1.07183484e-02  6.17098659e-02 -1.87030900e-02\n",
      " -3.15455459e-02  6.68333247e-02 -1.41046280e-02  8.62716585e-02\n",
      " -1.48623949e-02  5.37717938e-02 -1.29324524e-02  1.67964585e-02\n",
      " -4.44365218e-02 -6.23810776e-02 -7.90728256e-02 -4.95423600e-02\n",
      "  1.25261315e-03  4.00873311e-02  1.70643963e-02 -4.64960292e-04\n",
      "  2.22662231e-03 -3.12662348e-02 -6.91630840e-02  1.17354542e-02\n",
      " -4.16256450e-02 -5.11133869e-04 -1.77616663e-02  3.31737497e-03\n",
      " -1.13827839e-01  1.64234731e-02  1.62764415e-02  7.90745206e-03\n",
      " -1.41127896e-03 -8.30673724e-02  4.52377126e-02 -2.67447755e-02\n",
      " -2.77510867e-03 -1.41600296e-02 -9.37984362e-02 -2.35230746e-33\n",
      "  1.93260778e-02 -1.37045067e-02 -7.67222345e-02  4.48148847e-02\n",
      "  3.29022370e-02 -6.54888600e-02 -2.96403673e-02  1.54925184e-02\n",
      " -6.24234963e-04 -5.92622627e-03 -2.39993110e-02  3.02323438e-02\n",
      " -2.22235359e-02 -6.77239373e-02 -5.42394072e-02  7.37578347e-02\n",
      "  6.31849617e-02  1.37538500e-02  4.22320403e-02 -6.73834085e-02\n",
      "  8.57119337e-02  6.23279959e-02 -4.75444160e-02 -3.68247032e-02\n",
      " -7.52116889e-02  2.01771501e-03  2.52615437e-02  6.00019768e-02\n",
      " -6.09856844e-02 -7.83072263e-02 -8.02874714e-02 -7.31291398e-02\n",
      "  1.31354913e-01  2.48917993e-02 -1.09841721e-03 -1.51336808e-02\n",
      "  1.90773141e-02 -7.09718093e-02 -3.77092510e-02  4.59427536e-02\n",
      "  2.82679871e-02 -2.46650446e-02 -1.03399307e-01  7.09775090e-02\n",
      " -7.83411711e-02 -3.00897664e-04  1.33227715e-02  1.08018694e-02\n",
      "  8.82575363e-02 -3.50563675e-02  3.12922597e-02  1.74330492e-02\n",
      " -6.98357262e-03 -2.51511130e-02  5.63720316e-02 -1.46992402e-02\n",
      "  7.72929415e-02  2.28991285e-02  5.96854277e-02  3.16895656e-02\n",
      "  5.06230220e-02  4.52441759e-02  6.20269403e-02  5.57632893e-02\n",
      "  5.84913157e-02  2.41841245e-02  3.04389261e-02 -9.71055496e-03\n",
      " -4.40748548e-03  5.23180962e-02  2.57188566e-02  3.18244994e-02\n",
      "  1.53043941e-02 -6.18297569e-02 -5.18141277e-02 -3.33829597e-02\n",
      "  3.55804376e-02 -5.86455353e-02  8.29407107e-03  1.84720643e-02\n",
      " -5.76940030e-02 -7.31930509e-02 -1.68060362e-02  7.49681070e-02\n",
      "  3.17593850e-02 -7.48584718e-02  3.15407738e-02  3.14105116e-02\n",
      " -4.03676480e-02  8.90051126e-02 -1.05621656e-02  7.11647347e-02\n",
      "  6.81486912e-04  3.96462418e-02  2.03902107e-02 -4.80199525e-08\n",
      "  9.22648087e-02 -6.23538233e-02 -9.02778730e-02 -3.36487070e-02\n",
      " -1.90331675e-02 -6.63311034e-02  6.58052266e-02  1.53661119e-02\n",
      " -9.46060638e-04 -3.73437554e-02  5.78399785e-02 -4.25002575e-02\n",
      " -3.95265454e-03 -3.01952362e-02 -5.14906039e-03 -1.97773725e-02\n",
      " -1.22206938e-02  4.23905998e-02 -7.55174011e-02 -1.66155957e-02\n",
      "  4.61608581e-02 -2.18708301e-03  5.33787012e-02 -9.53861251e-02\n",
      " -2.25929022e-02  1.45584801e-02 -5.27600534e-02  9.89303663e-02\n",
      "  3.08563579e-02  1.63327847e-02 -1.25880791e-02 -3.96132916e-02\n",
      "  5.23618199e-02  6.72195433e-03 -6.92149717e-03 -2.42305081e-02\n",
      " -2.01523647e-01 -3.70532461e-02 -3.76912057e-02  4.59257374e-03\n",
      " -3.93986031e-02 -1.26187965e-01 -1.23203188e-01  7.93766789e-03\n",
      " -2.19814084e-03 -3.68949887e-03 -5.86532131e-02  6.54185116e-02\n",
      " -4.58216853e-02  5.94738871e-02  3.48698981e-02 -1.68443820e-03\n",
      " -1.07834954e-02 -3.67421657e-02 -5.04150875e-02  2.46239882e-02\n",
      "  5.60238212e-02 -3.22460383e-02  5.92523441e-02 -7.21893320e-03\n",
      " -1.16845360e-03  1.09689673e-02 -2.93830466e-02  9.89041850e-03]\n",
      "\n",
      "---\n",
      "\n",
      "Document ID: 0ce6294f-7797-4d46-984d-7e7523b36591\n",
      "document_content: page_content='\"GBR-7001\": \"Twin-size daybed with trundle in brushed silver metal, ideal for guest rooms or small spaces. Includes two comfortable twin mattresses. Manufactured by Guestroom Gadgets. Bed dimensions: 79\\\"L x 42\\\"W x 34\\\"H.\",\n",
      "  \"GBR-7002\": \"Wall art set featuring three abstract prints in blue and grey tones, framed in light wood. Each frame measures 24\\\"W x 36\\\"H. Adds a modern touch to guest bedrooms. Produced by Artistic Expressions.\",\n",
      "  \"GBR-7003\": \"Set of two bedside lamps in brushed nickel with white fabric shades. Offers a soft, ambient light suitable for reading or relaxing in bed. Dimensions per lamp: 12\\\"W x 24\\\"H. Manufactured by Bright Nights.\",' metadata={'file_name': 'test_data'}\n",
      "Metadata: {'file_name': 'test_data'}\n",
      "Vector: [-4.84835505e-02 -7.24295825e-02 -2.35167164e-02  2.17878446e-02\n",
      "  9.35974997e-03  1.42880604e-02  3.28496024e-02  3.35450061e-02\n",
      " -5.72770424e-02  1.40334712e-02 -4.41163331e-02 -7.07474276e-02\n",
      "  3.42672691e-02  2.52093375e-02  1.47540579e-02  4.18688096e-02\n",
      "  2.44362988e-02 -7.71505684e-02  3.69401611e-02  5.27733341e-02\n",
      " -2.28904374e-02 -4.82927226e-02  6.46729991e-02  1.65928446e-03\n",
      " -2.40312926e-02  4.13742010e-03 -4.21608761e-02 -4.06060554e-03\n",
      "  1.47028333e-02 -6.80569336e-02  7.83552825e-02  6.49518669e-02\n",
      " -1.30223222e-02  1.64937433e-02  7.45507926e-02 -5.93990199e-02\n",
      " -2.69198902e-02  1.90005675e-02 -7.32285678e-02 -2.96079554e-02\n",
      " -3.72456796e-02 -3.14292125e-02  1.86431203e-02  1.67439152e-02\n",
      " -4.06401530e-02 -1.94005703e-03  1.02299722e-02 -1.79438144e-02\n",
      " -3.84199060e-02 -6.40651658e-02  7.23528489e-02 -3.15407999e-02\n",
      " -2.63728462e-02  1.13886535e-01  7.83289671e-02  2.37230584e-03\n",
      " -1.11912973e-01 -1.25225773e-02  6.76652640e-02 -4.47354428e-02\n",
      "  4.59572710e-02  1.84722468e-02  3.60028073e-02 -7.68138766e-02\n",
      " -5.51762478e-03  3.32580768e-02 -1.00520000e-01 -5.36024347e-02\n",
      "  2.63442722e-04 -3.85538936e-02 -4.86936420e-02  1.81266349e-02\n",
      " -2.72617359e-02  4.86468971e-02 -4.68376838e-02 -2.77285445e-02\n",
      "  5.86647987e-02 -2.87070293e-02 -3.65025736e-02  8.09894991e-04\n",
      " -5.88319972e-02  7.58601539e-03  1.28374361e-02  1.10413641e-01\n",
      " -5.28459847e-02 -6.36746138e-02  4.58613485e-02  7.25203529e-02\n",
      " -8.92185718e-02 -6.80231825e-02  1.76835302e-02  2.79443525e-02\n",
      " -4.10182700e-02  6.46072906e-03 -4.07194197e-02  2.41638999e-02\n",
      " -4.27019671e-02 -3.21335867e-02  4.71626781e-02  4.36311066e-02\n",
      "  4.92315227e-03  1.61293466e-02  1.06914051e-01  2.88878959e-02\n",
      " -6.25752881e-02 -7.25817233e-02 -7.42693106e-03  7.79831111e-02\n",
      "  3.69850248e-02 -6.80154189e-02  3.30888815e-02  3.26239504e-02\n",
      " -1.32132350e-02  9.96851698e-02  1.99414953e-03 -1.13661841e-01\n",
      "  6.92674816e-02  6.67599663e-02  1.61345303e-01  4.78398101e-03\n",
      "  1.02353789e-01  4.52059135e-02  5.43898456e-02 -4.42108251e-02\n",
      " -7.25581646e-02 -7.99194798e-02  3.06646395e-02  6.30594018e-33\n",
      " -1.22549608e-02  6.94007501e-02 -2.88169552e-02 -2.75441655e-03\n",
      "  5.67404330e-02  5.02974866e-03 -1.58245806e-02  1.23168670e-01\n",
      "  4.86292355e-02  4.19022441e-02 -3.00989859e-02 -1.92455482e-02\n",
      "  5.40416315e-02  7.72112831e-02 -1.08429557e-02 -2.86383312e-02\n",
      " -1.03557222e-02  2.94837300e-02 -4.45646346e-02  9.61603411e-03\n",
      " -3.74945179e-02  1.02519780e-01  7.67736807e-02  6.67773336e-02\n",
      " -4.09581931e-03 -5.38572744e-02  3.76525968e-02 -3.85285690e-02\n",
      "  2.28625406e-02 -2.26973444e-02  4.53010350e-02 -5.46201132e-02\n",
      "  9.22077671e-02 -3.02898791e-03 -2.36789789e-02 -2.07230002e-02\n",
      "  3.13705988e-02 -3.44841853e-02 -6.39757514e-02  4.95196581e-02\n",
      " -5.91713451e-02  4.82302606e-02  3.85169163e-02  2.16075685e-02\n",
      "  2.71606240e-02  9.05401632e-02  5.05560972e-02  3.14889960e-02\n",
      " -1.30939549e-02 -7.94415828e-03 -5.25515564e-02 -2.58973651e-02\n",
      " -1.35708526e-01 -1.54192625e-02 -4.06161742e-03  3.21316421e-02\n",
      "  9.22712311e-03 -1.97520088e-02  1.21095374e-01  9.30139236e-03\n",
      "  2.31347252e-02  1.27975652e-02 -5.57509298e-03 -1.05336741e-01\n",
      " -4.44770083e-02 -6.12538345e-02  1.55502791e-02 -5.80676831e-03\n",
      " -1.00987002e-01 -6.80850372e-02 -5.99207394e-02 -3.33440974e-02\n",
      "  8.64082426e-02 -5.95638826e-02  2.58848034e-02 -4.28767502e-02\n",
      " -3.48944031e-02 -7.87575543e-02 -3.06292158e-02  3.75999250e-02\n",
      " -8.67094845e-02  5.23867756e-02  3.29026170e-02 -5.88210125e-04\n",
      " -6.95501193e-02 -5.69500700e-02  2.28259675e-02 -2.24130806e-02\n",
      " -1.26303077e-01 -1.62903927e-02 -2.01288741e-02 -1.51410336e-02\n",
      " -4.07378841e-03 -7.70531893e-02 -6.38123527e-02 -5.93199486e-33\n",
      "  3.12721916e-02 -4.08733152e-02 -6.95650429e-02  7.67678618e-02\n",
      "  7.63534382e-02  1.00985309e-02 -2.05894909e-03  1.35498326e-02\n",
      "  1.43131688e-02 -1.53190605e-02  8.45652148e-02 -2.79446524e-02\n",
      "  4.20182645e-02  2.50818580e-03  4.65642028e-02 -1.81119144e-02\n",
      " -1.26530025e-02  2.02068519e-02 -1.04634717e-01  3.78095470e-02\n",
      "  4.90632467e-02  6.01424463e-02 -4.24285084e-02  1.01830093e-02\n",
      " -1.22675160e-02  4.68048900e-02  2.87847538e-02 -2.25141719e-02\n",
      " -3.52512784e-02  8.28685611e-02 -8.12334642e-02 -6.41366914e-02\n",
      "  9.16213077e-03  4.94576208e-02  3.99966650e-02 -5.53434491e-02\n",
      "  4.99475002e-02 -6.45773113e-02 -5.30349649e-02  4.00400758e-02\n",
      "  4.20921519e-02  1.71393733e-02 -1.30893579e-02 -3.37201240e-03\n",
      " -4.38738801e-02 -4.46520559e-03 -6.47641346e-02 -1.64101762e-03\n",
      "  8.20806697e-02 -3.40548642e-02  3.75194773e-02  1.54929329e-02\n",
      " -2.91824397e-02 -7.30129406e-02 -2.67260000e-02 -8.97052810e-02\n",
      " -1.79173294e-02  2.18350552e-02  1.10341184e-01  1.13185756e-01\n",
      "  5.78166842e-02 -5.68104088e-02  3.06551233e-02  5.31996302e-02\n",
      " -6.49631545e-02  3.31540518e-02 -6.74665393e-03  3.37673631e-03\n",
      "  5.40469997e-02  3.40791270e-02  1.76344998e-02 -4.31810282e-02\n",
      "  4.44060890e-03  1.34466253e-02 -1.04642345e-03 -3.59294601e-02\n",
      "  6.50125369e-02 -4.72451970e-02  7.54280984e-02  1.49411708e-03\n",
      "  5.88050997e-03  2.73760501e-02  3.13720033e-02 -1.95300449e-02\n",
      "  3.02501675e-02 -6.33321553e-02  2.80951224e-02  6.60606697e-02\n",
      " -1.62519757e-02 -4.74526025e-02 -5.78234941e-02  7.43231624e-02\n",
      " -3.41644064e-02  1.63456537e-02  2.09449306e-02 -5.15604484e-08\n",
      " -4.15928736e-02 -2.29505133e-02 -4.32596728e-02  5.11433044e-03\n",
      "  1.00360252e-03 -1.09782480e-01  8.86935890e-02  2.12626439e-03\n",
      " -5.32683805e-02  3.22341308e-04  1.08481757e-01 -7.85251409e-02\n",
      "  3.55187594e-03 -2.18880493e-02  3.22782733e-02 -3.14373011e-03\n",
      " -1.30411601e-02  3.98579985e-02 -9.94556304e-03 -2.60742959e-02\n",
      "  7.02417269e-02  1.60428621e-02  4.65700775e-02 -8.13502297e-02\n",
      "  1.31930187e-02  6.70861378e-02 -2.64476500e-02  8.49643573e-02\n",
      "  2.34786421e-02 -3.72880660e-02  1.36885941e-01  2.98511647e-02\n",
      "  4.27369438e-02 -3.50532345e-02  1.13280490e-02 -2.46722251e-02\n",
      " -5.18708862e-02  4.85005081e-02  2.11157985e-02 -8.89108609e-03\n",
      " -6.29103705e-02 -1.03920847e-01 -7.67072812e-02 -1.84995458e-02\n",
      "  6.15197010e-02 -7.54510611e-02 -1.58609301e-02  1.32614477e-02\n",
      " -6.36529326e-02  9.90051925e-02  3.44625078e-02 -1.33110080e-02\n",
      "  1.68100167e-02  6.03343509e-02  1.56882405e-02 -6.44581541e-02\n",
      " -3.61531451e-02  1.23673966e-02 -5.43734208e-02 -7.72754941e-03\n",
      "  1.21788373e-02 -3.61610582e-04 -8.21399987e-02  5.40154614e-03]\n",
      "\n",
      "---\n",
      "\n",
      "Document ID: 48ac1bcb-911b-4686-b930-454d47b20d15\n",
      "document_content: page_content='\"BMT-8001\": \"Industrial-style pool table with a slate top and black felt, includes cues, balls, and a rack. Perfect for entertaining and game nights in finished basements. Produced by Billiard Masters. Dimensions: 96\\\"L x 52\\\"W x 32\\\"H.\",\n",
      "  \"BMT-8002\": \"Leather home theater recliner set in black, includes four connected seats with individual cup holders and storage compartments. Offers a luxurious movie-watching experience. Made by CinemaComfort. Dimensions per seat: 22\\\"W x 40\\\"D x 40\\\"H.\",\n",
      "  \"BMT-8003\": \"Adjustable height pub table set with four stools, featuring a rustic wood finish and black metal frame. Ideal for casual dining or socializing in basements. Produced by Casual Home. Table dimensions: 36\\\"W x 36\\\"D x 42\\\"H, Stool dimensions: 15\\\"W x 15\\\"D x 30\\\"H.\"\n",
      "}' metadata={'file_name': 'test_data'}\n",
      "Metadata: {'file_name': 'test_data'}\n",
      "Vector: [ 5.37512265e-02 -3.20534445e-02 -4.37556487e-03 -1.31733147e-02\n",
      " -8.13696533e-02  5.28819747e-02  3.26398909e-02  5.23796417e-02\n",
      " -1.79521572e-02 -1.38831073e-02 -6.32598996e-02 -4.42483239e-02\n",
      "  5.72322607e-02  4.15026657e-02 -6.03638589e-02  4.88654338e-02\n",
      "  1.14550479e-01 -5.20966239e-02  2.97054313e-02  5.29593378e-02\n",
      " -3.88931260e-02 -4.47948799e-02  4.65655625e-02 -5.92917623e-03\n",
      " -6.13921024e-02  2.10878663e-02  2.54746992e-02  9.21998322e-02\n",
      " -4.62359749e-02 -6.41490221e-02 -2.54450075e-04  5.01522683e-02\n",
      "  7.96917155e-02 -1.17141493e-02  5.17233536e-02 -2.50918195e-02\n",
      " -4.85880189e-02 -2.98236143e-02 -2.28026491e-02 -5.64931426e-03\n",
      " -8.23599249e-02 -3.52540463e-02  5.04029728e-02  1.01474501e-01\n",
      "  1.37520917e-02  2.54712403e-02 -3.93872261e-02 -1.22035425e-02\n",
      " -2.99534127e-02  1.16461341e-03  3.08770512e-04  7.22484961e-02\n",
      "  2.07461081e-02  3.63525935e-02  6.35502040e-02 -1.31734004e-02\n",
      " -5.86560071e-02  1.66601762e-02  4.37130667e-02 -6.40340671e-02\n",
      "  4.24098335e-02  2.00832207e-02 -1.94680393e-02 -3.31719853e-02\n",
      "  1.68941189e-02  4.48893867e-02 -6.35157600e-02  1.59106217e-02\n",
      "  1.06599545e-02 -5.87106263e-03 -4.64872979e-02  5.76469749e-02\n",
      " -3.79396253e-03 -3.35820839e-02 -1.29519869e-02 -5.57354502e-02\n",
      "  3.93183641e-02 -5.63457049e-02 -3.93890515e-02  2.93423608e-02\n",
      " -7.81261735e-03  1.38064791e-02 -5.47758816e-03  4.04269882e-02\n",
      " -3.05282939e-02 -1.34462873e-02 -1.31565705e-02  7.28269592e-02\n",
      " -4.64390442e-02 -6.97289333e-02 -4.63312156e-02  5.82408793e-02\n",
      " -1.11382253e-01 -2.99968477e-02 -4.02390026e-02  3.48876715e-02\n",
      " -2.05819365e-02 -5.39269671e-02  8.21612924e-02  7.49467984e-02\n",
      "  3.85294184e-02  7.27697685e-02  5.08953072e-02  6.90901354e-02\n",
      " -2.72892006e-02 -6.02266416e-02  8.63659307e-02  1.17768183e-01\n",
      "  6.54644668e-02 -1.00132063e-01 -2.25087889e-02  1.42752868e-03\n",
      "  2.72659436e-02  3.15804407e-02 -5.79172596e-02  5.41277155e-02\n",
      "  2.12194715e-02 -2.72438414e-02  6.80470169e-02 -6.83598593e-02\n",
      "  8.50921720e-02  5.46294451e-02 -3.32704820e-02  2.15711221e-02\n",
      " -7.28003681e-02 -6.94362214e-03  6.64087571e-03  5.17679814e-33\n",
      " -4.00507301e-02  2.55343821e-02  2.97341533e-02  2.86149103e-02\n",
      "  9.21374261e-02  1.11777475e-02  2.87232138e-02  7.75270769e-03\n",
      "  5.59192291e-03  6.44787624e-02 -2.05318481e-02 -7.58879632e-02\n",
      "  1.22977803e-02  3.81468935e-03  4.53807116e-02  4.19108430e-03\n",
      " -5.02444245e-02  4.06547897e-02 -4.81428541e-02 -2.18731910e-02\n",
      " -7.93548524e-02  8.71044919e-02 -1.19054271e-03 -3.22897322e-02\n",
      " -1.93154532e-02  7.09128305e-02  2.72690784e-02  4.10274342e-02\n",
      "  1.67258885e-02  8.24609597e-04  4.33950201e-02  1.95145309e-02\n",
      " -6.32895380e-02 -1.98426880e-02 -3.67194824e-02 -4.95717078e-02\n",
      " -1.00046858e-01 -1.32506927e-02 -8.52382183e-03 -7.09928721e-02\n",
      " -7.78089985e-02  6.55117780e-02 -7.69879818e-02  3.48311290e-02\n",
      " -4.39363644e-02 -2.19841916e-02  6.69250265e-02 -3.25537398e-02\n",
      " -9.64043196e-03  2.69567184e-02 -5.21529950e-02  1.01223320e-01\n",
      "  1.27705727e-02 -8.44913349e-02 -3.81089188e-02 -6.34052157e-02\n",
      "  1.63218863e-02 -1.06721474e-02  1.42834429e-02  6.26171604e-02\n",
      "  1.30695790e-01  4.41121310e-02 -4.62995730e-02  8.22591409e-03\n",
      " -3.17677073e-02  2.85205618e-02  3.10820136e-02 -3.82575281e-02\n",
      "  1.05790116e-01 -5.61642125e-02 -1.12327309e-02 -6.49364386e-03\n",
      "  1.01992391e-01 -5.15927859e-02 -1.35276944e-03  1.83314807e-03\n",
      " -3.05923428e-02 -4.37566824e-02 -4.39839140e-02 -7.02569215e-03\n",
      "  1.93363726e-02  1.43005187e-03  6.47419915e-02 -5.65835834e-02\n",
      " -6.78299069e-02 -6.69940859e-02  3.05208061e-02 -7.42278844e-02\n",
      " -1.74267162e-02 -6.97547421e-02 -3.46022993e-02 -1.29479587e-01\n",
      " -2.50597149e-02  1.00375200e-02 -4.51980568e-02 -6.05871792e-33\n",
      "  4.68968786e-02  2.09449814e-03 -1.12037078e-01 -7.41083995e-02\n",
      " -1.77891441e-02 -2.44913157e-02  2.19395384e-02 -1.97061785e-02\n",
      " -1.21768694e-02  1.62043292e-02 -7.99728744e-03  7.00765327e-02\n",
      "  2.69228891e-02 -3.42481248e-02  3.11696678e-02  6.29767254e-02\n",
      "  3.82120386e-02 -5.09722866e-02 -5.54165356e-02  2.98584346e-03\n",
      "  6.47122264e-02  1.03070579e-01 -1.32717695e-02  3.84707376e-02\n",
      " -5.28490990e-02  3.07396036e-02  4.54390943e-02 -4.77152467e-02\n",
      " -4.85451370e-02  6.22391924e-02 -8.09823573e-02 -9.86922234e-02\n",
      "  2.78568640e-02  7.76622444e-02 -3.15218396e-03 -7.88058713e-02\n",
      "  1.30201727e-02  1.82390455e-02 -3.81361172e-02 -4.84479498e-03\n",
      "  5.04677705e-02  1.76054928e-02 -3.06971837e-02  2.74102874e-02\n",
      "  5.50688133e-02  4.80221733e-02 -4.10456024e-02 -5.10454141e-02\n",
      "  3.35818045e-02 -6.96987137e-02 -5.18839024e-02 -8.77793692e-03\n",
      " -1.30142849e-02 -1.37688383e-01  7.96179548e-02 -4.67384271e-02\n",
      " -3.04438472e-02 -5.84608503e-03  1.63501538e-02  3.36683393e-02\n",
      " -1.83675718e-02  9.61942002e-02 -1.46961063e-02  6.74874634e-02\n",
      "  1.89719349e-02  8.64070207e-02 -7.96438158e-02 -5.23911603e-02\n",
      " -3.14016826e-02  5.36243729e-02 -7.47147202e-02 -1.50412843e-02\n",
      " -2.39146408e-02  4.60797623e-02 -3.71766686e-02 -9.20947734e-03\n",
      "  6.52292818e-02  7.77108297e-02 -7.92237464e-03  5.47229573e-02\n",
      " -5.36845485e-03 -1.60622764e-02  1.08253263e-01  1.84168220e-02\n",
      "  5.33789136e-02 -1.20239556e-02 -4.31267126e-03  8.25665221e-02\n",
      " -3.74711975e-02  5.25894575e-02  1.51511673e-02  2.00710129e-02\n",
      " -1.91590693e-02  3.88005637e-02  4.98529710e-02 -5.42868008e-08\n",
      " -2.51296014e-02 -1.85862128e-02 -5.38638532e-02  4.64001857e-02\n",
      " -7.40415007e-02 -1.32540017e-01  5.56472056e-02  3.09469886e-02\n",
      "  3.43727842e-02 -4.19315184e-03  3.09046498e-03 -6.77485093e-02\n",
      "  7.01780058e-03  3.66346724e-02 -7.53124729e-02  4.12101187e-02\n",
      " -5.54949269e-02  1.24703366e-02 -2.74524856e-02  4.56116311e-02\n",
      "  2.62892246e-03 -4.10228521e-02  7.63523802e-02  2.32256800e-02\n",
      "  4.26447159e-03 -2.21975967e-02 -9.37178209e-02 -2.33663470e-02\n",
      "  7.90369883e-02 -4.44678739e-02  7.13805482e-02  7.86505453e-03\n",
      "  2.42113578e-03 -4.18056287e-02  4.79579829e-02 -2.87325419e-02\n",
      " -8.54560435e-02  5.75834000e-03  1.40705565e-02  6.58503026e-02\n",
      " -7.28723407e-02 -1.26763970e-01 -4.78467867e-02 -1.22534586e-02\n",
      "  1.26145035e-01  2.25489084e-02 -1.19237244e-01 -3.74937989e-02\n",
      " -1.39884069e-03  3.65904570e-02  2.59622671e-02 -3.84615324e-02\n",
      " -4.35587164e-04 -1.70761980e-02  8.18111002e-02  5.85841127e-02\n",
      " -1.72623880e-02  5.16681150e-02  5.11888117e-02 -7.87458103e-03\n",
      "  7.85307810e-02  2.15158034e-02 -1.10782325e-01 -2.10250188e-02]\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_vectors = vector_store.index.ntotal\n",
    "\n",
    "# Iterate through all stored vectors and their metadata\n",
    "for i in range(num_vectors):\n",
    "    # Retrieve the vector\n",
    "    vector = vector_store.index.reconstruct(i)  # Get the embedding vector\n",
    "    # Retrieve the corresponding document metadata\n",
    "    doc_id_key = list(vector_store.docstore._dict.keys())[i]\n",
    "    doc_id_value = list(vector_store.docstore._dict.values())[i]\n",
    "    document = vector_store.docstore._dict[doc_id_key]\n",
    "    \n",
    "    # Print details\n",
    "    print(f\"Document ID: {doc_id_key}\")\n",
    "    print(f\"document_content: {doc_id_value}\")\n",
    "    print(f\"Metadata: {document.metadata}\")\n",
    "    print(f\"Vector: {vector}\")\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\anupam project\\genai\\env\\lib\\site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in d:\\anupam project\\genai\\env\\lib\\site-packages (from sentence-transformers) (4.67.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\anupam project\\genai\\env\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\anupam project\\genai\\env\\lib\\site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in d:\\anupam project\\genai\\env\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in d:\\anupam project\\genai\\env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anupam project\\genai\\env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\anupam project\\genai\\env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anupam project\\genai\\env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\anupam project\\genai\\env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anupam project\\genai\\env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\anupam project\\genai\\env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\anupam project\\genai\\env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\anupam project\\genai\\env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anupam project\\genai\\env\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\anupam project\\genai\\env\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anupam project\\genai\\env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anupam project\\genai\\env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in d:\\anupam project\\genai\\env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\anupam project\\genai\\env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anupam project\\genai\\env\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anupam project\\genai\\env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anupam project\\genai\\env\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anupam project\\genai\\env\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anupam project\\genai\\env\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anupam project\\genai\\env\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 28.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.0 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 18.1 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "   ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/44.8 MB 12.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.0/44.8 MB 12.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.3/44.8 MB 11.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.1/44.8 MB 10.3 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 11.0/44.8 MB 10.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 13.4/44.8 MB 10.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 15.7/44.8 MB 10.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.3/44.8 MB 10.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.6/44.8 MB 10.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.7/44.8 MB 9.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.4/44.8 MB 8.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.5/44.8 MB 8.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.3/44.8 MB 8.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.3/44.8 MB 7.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 24.9/44.8 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.0/44.8 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.8/44.8 MB 7.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 30.4/44.8 MB 7.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.0/44.8 MB 8.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 36.2/44.8 MB 8.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 37.2/44.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.1/44.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.4/44.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.6/44.8 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.6/44.8 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 MB 8.2 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sentence-transformers\n",
      "Successfully installed scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.3.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x143906b0e90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = document_chunker_langchain(directory_path='./Document/test',\n",
    "                        model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                        chunk_size=256)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FAISS' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mdocs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(docs))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(docs[keys[\u001b[38;5;241m0\u001b[39m]])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FAISS' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "keys = list(docs.keys())\n",
    "print(len(docs))\n",
    "print(docs[keys[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.save_pretrained(\"model/tokenizer\")\n",
    "model.save_pretrained(\"model/embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"/model/tokenizer\") \n",
    "    model = AutoModel.from_pretrained(\"/model/embedding\")\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True) \n",
    "    \n",
    "    # Generate the embeddings \n",
    "    with torch.no_grad():    \n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "    return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(doc_store):\n",
    "    vector_store = {}\n",
    "    for doc_id, chunks in doc_store.items():\n",
    "        doc_vectors = {}\n",
    "        for chunk_id, chunk_dict in chunks.items():\n",
    "            # Generate an embedding for each chunk of text\n",
    "            doc_vectors[chunk_id] = compute_embeddings(chunk_dict.get(\"text\"))\n",
    "        # Store the document's chunk embeddings mapped by their chunk UUIDs\n",
    "        vector_store[doc_id] = doc_vectors\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matches(vector_store, query_str, top_k):\n",
    "    \"\"\"\n",
    "    This function takes in a vector store dictionary, a query string, and an int 'top_k'.\n",
    "    It computes embeddings for the query string and then calculates the cosine similarity against every chunk embedding in the dictionary.\n",
    "    The top_k matches are returned based on the highest similarity scores.\n",
    "    \"\"\"\n",
    "    # Get the embedding for the query string\n",
    "    query_str_embedding = np.array(compute_embeddings(query_str))\n",
    "    scores = {}\n",
    "\n",
    "    # Calculate the cosine similarity between the query embedding and each chunk's embedding\n",
    "    for doc_id, chunks in vector_store.items():\n",
    "        for chunk_id, chunk_embedding in chunks.items():\n",
    "            chunk_embedding_array = np.array(chunk_embedding)\n",
    "            # Normalize embeddings to unit vectors for cosine similarity calculation\n",
    "            norm_query = np.linalg.norm(query_str_embedding)\n",
    "            norm_chunk = np.linalg.norm(chunk_embedding_array)\n",
    "            if norm_query == 0 or norm_chunk == 0:\n",
    "                # Avoid division by zero\n",
    "                score = 0\n",
    "            else:\n",
    "                score = np.dot(chunk_embedding_array, query_str_embedding) / (norm_query * norm_chunk)\n",
    "\n",
    "            # Store the score along with a reference to both the document and the chunk\n",
    "            scores[(doc_id, chunk_id)] = score\n",
    "\n",
    "    # Sort scores and return the top_k results\n",
    "    sorted_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)[:top_k]\n",
    "    top_results = [(doc_id, chunk_id, score) for ((doc_id, chunk_id), score) in sorted_scores]\n",
    "\n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_matches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWall-mounted electric fireplace with realistic LED flames\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 8\u001b[0m, in \u001b[0;36mcompute_matches\u001b[1;34m(vector_store, query_str, top_k)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis function takes in a vector store dictionary, a query string, and an int 'top_k'.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mIt computes embeddings for the query string and then calculates the cosine similarity against every chunk embedding in the dictionary.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mThe top_k matches are returned based on the highest similarity scores.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Get the embedding for the query string\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m query_str_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(compute_embeddings(query_str))\n\u001b[0;32m      9\u001b[0m scores \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate the cosine similarity between the query embedding and each chunk's embedding\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "matches = compute_matches(vector_store=vector_store,\n",
    "                            query_str=\"Wall-mounted electric fireplace with realistic LED flames\",\n",
    "                            top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 23 key-value pairs and 201 tensors from ./llama_model/tinyllama-1.1b-chat-v1.0.Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = tinyllama_tinyllama-1.1b-chat-v1.0\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 2048\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 2048\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 22\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 5632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 64\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 4\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,61249]   = [\" t\", \"e r\", \"i n\", \" a\", \"e n...\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% for message in messages %}\\n{% if m...\n",
      "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   45 tensors\n",
      "llama_model_loader: - type q8_0:  156 tensors\n",
      "llm_load_vocab: control token:      2 '</s>' is not marked as EOG\n",
      "llm_load_vocab: control token:      1 '<s>' is not marked as EOG\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 3\n",
      "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 2048\n",
      "llm_load_print_meta: n_layer          = 22\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 4\n",
      "llm_load_print_meta: n_rot            = 64\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 64\n",
      "llm_load_print_meta: n_embd_head_v    = 64\n",
      "llm_load_print_meta: n_gqa            = 8\n",
      "llm_load_print_meta: n_embd_k_gqa     = 256\n",
      "llm_load_print_meta: n_embd_v_gqa     = 256\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 5632\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 1B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 1.10 B\n",
      "llm_load_print_meta: model size       = 1.09 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = tinyllama_tinyllama-1.1b-chat-v1.0\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 2 '</s>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 2 '</s>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q8_0) (and 200 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =  1114.91 MiB\n",
      "..........................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 512\n",
      "llama_new_context_with_model: n_ctx_per_seq = 512\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 10000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (2048) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init:        CPU KV buffer size =    11.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   11.00 MiB, K (f16):    5.50 MiB, V (f16):    5.50 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    66.50 MiB\n",
      "llama_new_context_with_model: graph nodes  = 710\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | AMX_INT8 = 0 | FMA = 0 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'tinyllama_tinyllama-1.1b-chat-v1.0', 'general.architecture': 'llama', 'llama.context_length': '2048', 'llama.rope.dimension_count': '64', 'llama.embedding_length': '2048', 'llama.block_count': '22', 'llama.feed_forward_length': '5632', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '7', 'llama.attention.head_count_kv': '4', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.chat_template': \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% for message in messages %}\n",
      "{% if message['role'] == 'user' %}\n",
      "{{ '<|user|>\n",
      "' + message['content'] + eos_token }}\n",
      "{% elif message['role'] == 'system' %}\n",
      "{{ '<|system|>\n",
      "' + message['content'] + eos_token }}\n",
      "{% elif message['role'] == 'assistant' %}\n",
      "{{ '<|assistant|>\n",
      "'  + message['content'] + eos_token }}\n",
      "{% endif %}\n",
      "{% if loop.last and add_generation_prompt %}\n",
      "{{ '<|assistant|>' }}\n",
      "{% endif %}\n",
      "{% endfor %}\n",
      "Using chat eos_token: </s>\n",
      "Using chat bos_token: <s>\n",
      "llama_perf_context_print:        load time =   70634.75 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   153 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   70636.53 ms /   154 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "import sys\n",
    "\n",
    "def stream_and_buffer(base_prompt, llm, max_tokens=800, stop=[\"Q:\", \"\\n\"], echo=True, stream=True):\n",
    "\n",
    "    # Formatting the base prompt\n",
    "    formatted_prompt = f\"Q: {base_prompt} A: \"\n",
    "\n",
    "    # Streaming the response from llm\n",
    "    response = llm(formatted_prompt, max_tokens=max_tokens, stop=stop, echo=echo, stream=stream)\n",
    "\n",
    "    buffer = \"\"\n",
    "\n",
    "    for message in response:\n",
    "        chunk = message['choices'][0]['text']\n",
    "        buffer += chunk\n",
    "\n",
    "        words = buffer.split(' ')\n",
    "        for word in words[:-1]:  \n",
    "            sys.stdout.write(word + ' ')  \n",
    "            sys.stdout.flush()  \n",
    "\n",
    "       \n",
    "        buffer = words[-1]\n",
    "\n",
    "    if buffer:\n",
    "        sys.stdout.write(buffer)\n",
    "        sys.stdout.flush()\n",
    "    print(buffer)\n",
    "def construct_prompt(system_prompt, retrieved_docs, user_query):\n",
    "    prompt = f\"\"\"{system_prompt}\n",
    "\n",
    "    Here is the retrieved context:\n",
    "    {retrieved_docs}\n",
    "\n",
    "    Here is the users query:\n",
    "    {user_query}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an intelligent search engine. You will be provided with some retrieved context, as well as the users query.\n",
    "\n",
    "Your job is to understand the request, and answer based on the retrieved context.\n",
    "\"\"\"\n",
    "\n",
    "retrieved_docs = \"\"\"\n",
    "Wall-mounted electric fireplace with realistic LED flames and heat settings. Features a black glass frame and remote control for easy operation. Ideal for adding warmth and ambiance. Manufactured by Hearth & Home. Dimensions: 50\"W x 6\"D x 21\"H.\n",
    "\"\"\"\n",
    "\n",
    "prompt = construct_prompt(system_prompt=system_prompt,\n",
    "                          retrieved_docs=retrieved_docs,\n",
    "                          user_query=\"bulb\")\n",
    "\n",
    "llm = Llama(model_path=\"./llama_model/tinyllama-1.1b-chat-v1.0.Q8_0.gguf\", n_gpu_layers=1)\n",
    "\n",
    "stream_and_buffer(prompt, llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "prompt_value = template.invoke(\n",
    "    {\n",
    "        \"name\": \"Bob\",\n",
    "        \"user_input\": \"What is your name?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a friendly chatbot who always responds in the style of a gentleman</s>\n",
      "<|user|>\n",
      "Where is mysore located?</s>\n",
      "<|assistant|>\n",
      "Myro is located in the Indian state of Karnataka, primarily in the Mandya district. The district is known for its rich cultural heritage and history, and is a popular destination for tourists and travelers. The city is located about 120 kilometers southeast of Bangalore, the state capital.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a gentleman\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Where is mysore located?\"},\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=100, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM MESSAGE:\n",
      "\n",
      "You are an intelligent search engine. You will be provided with some retrieved context, as well as the users query.\n",
      "\n",
      "Your job is to understand the request, and answer based on the retrieved context.\n",
      "\n",
      "\n",
      "HUMAN MESSAGE:\n",
      "\n",
      "Here is the retrieved context:\n",
      "\n",
      "Wall-mounted electric fireplace with realistic LED flames and heat settings. Features a black glass frame and remote control for easy operation. Ideal for adding warmth and ambiance. Manufactured by Hearth & Home. Dimensions: 50\"W x 6\"D x 21\"H.\n",
      "\n",
      "\n",
      "Here is the user's query:\n",
      "What are the dimensions of the fireplace?\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "def construct_prompt(system_prompt, retrieved_docs, user_query):\n",
    "    # Define the system message prompt\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    \n",
    "    # Define the human message prompt with placeholders\n",
    "    human_message = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "                                Here is the retrieved context:\n",
    "                                {retrieved_docs}\n",
    "\n",
    "                                Here is the user's query:\n",
    "                                {user_query}\n",
    "                                    \"\"\")\n",
    "    \n",
    "    # Combine the system and human messages into a ChatPromptTemplate\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    \n",
    "    # Format the chat prompt with the provided inputs\n",
    "    formatted_prompt = chat_prompt.format_messages(\n",
    "        retrieved_docs=retrieved_docs,\n",
    "        user_query=user_query\n",
    "    )\n",
    "    \n",
    "    return formatted_prompt\n",
    "\n",
    "# Inputs\n",
    "system_prompt = \"\"\"\n",
    "You are an intelligent search engine. You will be provided with some retrieved context, as well as the users query.\n",
    "\n",
    "Your job is to understand the request, and answer based on the retrieved context.\n",
    "\"\"\"\n",
    "\n",
    "retrieved_docs = \"\"\"\n",
    "Wall-mounted electric fireplace with realistic LED flames and heat settings. Features a black glass frame and remote control for easy operation. Ideal for adding warmth and ambiance. Manufactured by Hearth & Home. Dimensions: 50\"W x 6\"D x 21\"H.\n",
    "\"\"\"\n",
    "\n",
    "user_query = \"What are the dimensions of the fireplace?\"\n",
    "\n",
    "# Generate the prompt\n",
    "formatted_prompt = construct_prompt(system_prompt, retrieved_docs, user_query)\n",
    "# Display the formatted prompt\n",
    "for message in formatted_prompt:\n",
    "    print(f\"{message.type.upper()} MESSAGE:\")\n",
    "    print(message.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings # type: ignore\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from pypdf import PdfReader  \n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file using pypdf.\"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()  \n",
    "    return text\n",
    "\n",
    "def build_vector_store(directory_path, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", chunk_size=1024, chunk_overlap=0):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=int(os.environ.get(\"CHUNK_SIZE\", 1024)), chunk_overlap=chunk_overlap)\n",
    "    documents = []\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            base = os.path.basename(file_path)\n",
    "            sku = os.path.splitext(base)[0]\n",
    "            \n",
    "            # Check file type and extract text accordingly\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                text = extract_text_from_pdf(file_path)\n",
    "            elif filename.endswith(\".txt\"):\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    text = file.read()\n",
    "            else:\n",
    "                print(f\"Unsupported file type for {filename}, skipping.\")\n",
    "                continue\n",
    "            \n",
    "            chunks = text_splitter.split_text(text)\n",
    "            for chunk in chunks:\n",
    "                doc = Document(page_content=chunk, metadata={\"file_name\": sku})\n",
    "                documents.append(doc)\n",
    "\n",
    "    vector_store = FAISS.from_documents(documents, embeddings)\n",
    "    # pickle.dump(vector_store, open(\"./pickleDump/vector_store.pkl\", \"wb\"))\n",
    "    return vector_store\n",
    "\n",
    "def construct_prompt(system_prompt, retrieved_docs, user_query):\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    human_message = HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Here is the retrieved context:\n",
    "        {retrieved_docs}\n",
    "\n",
    "        Here is the user's query:\n",
    "        {user_query}\n",
    "        \"\"\"\n",
    "    )\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    formatted_prompt = chat_prompt.format_messages(retrieved_docs=retrieved_docs, user_query=user_query)\n",
    "    return formatted_prompt\n",
    "\n",
    "def query_llm(vector_store, query, llm_model=\"llama3.2\", temperature=0):\n",
    "    results = vector_store.similarity_search(query, k=5)\n",
    "    print('retrieved_docs', results)\n",
    "    retrieved_docs = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "    system_prompt = \"\"\"\n",
    "    You are a highly intelligent assistant designed to answer user questions strictly based on the provided document context. Here are your responsibilities:\n",
    "\n",
    "    1. **Use Provided Context Only**: Your answers must rely exclusively on the content retrieved from the document. Do not infer or generate information outside the document's scope.\n",
    "\n",
    "    2. **Handle Irrelevant Queries**: If the user's query is unrelated to the provided document, respond with: \n",
    "    \"The query is not relevant to the document.\"\n",
    "\n",
    "    3. **Include Page Numbers**: \n",
    "    - If the answer is based on the document, include the relevant page number(s) to indicate where the information was sourced.\n",
    "    - If the query is irrelevant, mention that the document context provided does not address the query and include the retrieved page numbers.\n",
    "\n",
    "    4. **Structured Output**:\n",
    "    - If the answer is based on the document, include specific details and context to ensure accuracy, along with the page number(s).\n",
    "    - If the query is irrelevant, explicitly state it without additional assumptions, mentioning the retrieved page numbers.\n",
    "\n",
    "    5. **Tone and Clarity**: Always maintain a professional and clear tone.\n",
    "\n",
    "    6. **Content Relevance**: If you feel the retrieved document and query are relevant, answer with an appropriate and clear response, referencing the specific page(s).\n",
    "\n",
    "    You will be provided with:\n",
    "    - **Retrieved Document Context**: The content relevant to the user's query, along with page number(s).\n",
    "    - **User Query**: The question or task from the user.\n",
    "\n",
    "    Your task:\n",
    "    - Analyze the retrieved document context and its page numbers.\n",
    "    - Answer the query based on the document, referencing the page number(s), or identify the query as irrelevant if the document does not contain an answer.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    formatted_prompt = construct_prompt(system_prompt, retrieved_docs, query)\n",
    "    llm = ChatOllama(model=llm_model, temperature=temperature)\n",
    "    final_prompt = \"\".join([message.content for message in formatted_prompt])\n",
    "    response = llm.invoke(final_prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nanupam\\AppData\\Local\\Temp\\ipykernel_20952\\1277766130.py:21: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
      "d:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./pickleDump/vector_store.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m         vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_vector_store\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Document/test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot there\u001b[39m\u001b[38;5;124m'\u001b[39m,vector_store)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m, in \u001b[0;36mbuild_vector_store\u001b[1;34m(directory_path, model_name, chunk_size, chunk_overlap)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_vector_store\u001b[39m(directory_path, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 21\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, chunk_overlap\u001b[38;5;241m=\u001b[39mchunk_overlap)\n\u001b[0;32m     23\u001b[0m     documents \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     emit_warning()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:84\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     warn_deprecated(\n\u001b[0;32m     75\u001b[0m         since\u001b[38;5;241m=\u001b[39msince,\n\u001b[0;32m     76\u001b[0m         removal\u001b[38;5;241m=\u001b[39mremoval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m constructor instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     81\u001b[0m     )\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sentence_transformers\\__init__.py:14\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     11\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchEncoding\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sentence_transformers\\evaluation\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mBinaryClassificationEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryClassificationEvaluator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEmbeddingSimilarityEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingSimilarityEvaluator\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mInformationRetrievalEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InformationRetrievalEvaluator\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sentence_transformers\\evaluation\\BinaryClassificationEvaluator.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Literal\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m average_precision_score\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sklearn\\__init__.py:84\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     81\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     87\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     ]\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sklearn\\utils\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isfinite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[0;32m     13\u001b[0m _NUMPY_NAMESPACE_NAMES \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray_api_compat.numpy\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21myield_namespaces\u001b[39m(include_numpy_namespaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\sklearn\\utils\\fixes.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\scipy\\stats\\__init__.py:610\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    605\u001b[0m \n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    609\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 610\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Import unused here but needs to stay until end of deprecation periode\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# See https://github.com/scipy/scipy/issues/15765#issuecomment-1875564522\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _mstats_basic \u001b[38;5;28;01mas\u001b[39;00m mstats_basic\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_mstats_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _find_repeats, theilslopes, siegelslopes\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\scipy\\stats\\distributions.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Author:  Travis Oliphant  2002-2011 with contributions from\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#          SciPy Developers 2004-2011\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#       instead of `git blame -Lxxx,+x`.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_distn_infrastructure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _continuous_distns\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _discrete_distns\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m integrate\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# to approximate the pdf of a continuous distribution given its cdf\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_finite_differences\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _derivative\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\scipy\\__init__.py:147\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[1;32m--> 147\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_importlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscipy.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\scipy\\integrate\\__init__.py:95\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m=============================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mIntegration and ODEs (:mod:`scipy.integrate`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m   solve_bvp     -- Solve a boundary value problem for a system of ODEs.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_quadrature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_odepack_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_quadpack_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32md:\\Anupam Project\\GenAI_v2\\env\\Lib\\site-packages\\scipy\\integrate\\_odepack_py.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124modeint\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mODEintWarning\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _odepack\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(\"./pickleDump/vector_store.pkl\"):\n",
    "        vector_store = build_vector_store(\"./Document/test\")\n",
    "        print('not there',vector_store)\n",
    "    else:\n",
    "        vector_store = pickle.load(open(\"./pickleDump/vector_store.pkl\", \"rb\"))\n",
    "        print('there',vector_store)\n",
    "    \n",
    "    user_query = \"Which device is capable of streaming music\"\n",
    "\n",
    "    response = query_llm(vector_store, user_query)\n",
    "    print(\"LLM Response:\")\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with vector store\n",
      "done with vector store\n",
      "started with llm\n",
      "retrieved_docs [Document(metadata={'file_name': 'SHARP Synappx GO Documentation (2)'}, page_content='Now see the device is assigned or not if not go to the bottom and check \\nthe MFP IP Address is in unassigned if its in that click on unassigned \\nand remove or delete unassigned devices. Now go check whether its \\nadded to your agent or not, if added go to workspaces and open your \\nlicensed workspace and check if your pc name or agent name is added or \\nnot. \\n \\nThen, \\n \\nSee the above picture for your clarification. \\nNow Select MFPs to associate with this workspace and confirm it on \\nclicking ok button on bottom. See the next image that will tell you the \\nMFP is assigned to your workspace. \\n \\nMFP is successfully Connected to your Workspace. \\n \\nNext, \\n \\n \\nINSTALL THE MOBILE APPLICATION IN YOUR MOBILE \\nPHONE \\nInstall the same stack mobile application in your mobile phone are in \\nyour device. \\nNow login with the same User Id which you logged in in your PC where \\nyou downloaded the above application. here you should not login with \\ndifferent user id or not to install different stack both should be same'), Document(metadata={'file_name': 'SHARP Synappx GO Documentation (2)'}, page_content='3.Synappx Collaboration HUB Installer. (Includes Synappx Go \\nDisplay Agent, Synappx Meeting (Link), Pen Software) \\nAll the three Applications can be Downloaded here.  \\n \\nSNMP Configuration: \\n* IP Range must be entered to automatically discover Sharp \\nMFPs \\n \\nEnter the IP address in IP Range start and Enter the IP address where it \\nends and then Click on download Now it will start downloading.  \\nAnd after downloading the application to your device you need to \\nextract the file then only it can be Installed to that particular device. \\n \\n \\nThen, \\nClick on Extract to Sharp Synappx GO MFP Agent, \\n \\nAfter extracting that file and open the file and click on setup to start \\ninstall the application. \\nNow Follow few steps to install the application in to your PC/Device. \\nThen check if its downloaded or not in (control panel  Programs  \\nPrograms and features). \\n \\nNext, \\n \\nOpen the stack which youre using and go to (Agents  agents and \\ndevices summary) and check if your Pc name or agent name is added or \\nnot.'), Document(metadata={'file_name': 'SHARP Synappx GO Documentation (2)'}, page_content='copy the latest UUID and Paste it on that Step 5 page or paste it \\non that Print, Share/Display and Checkin and go to the bottom and \\nsave that given id. \\n\\uf076 Step 7: After saving you will get the Step 4 Page, now here click \\non NFC Tag. \\n\\uf076   Step 8: It will ask you to select the workspace where you created \\nyour licensed workspace or in which workspace you want to \\nperform those operations. Here I have my workspace so I choose \\nmy workspace because I assigned MFP in my workspace. \\n\\uf076 Step 9: Click on the MFP which you assigned to your Workspace \\nto give the NFC tag. \\n\\uf076 Step 10: After clicking I will Automatically Assign that NFC tag \\nto that MFP successfully. \\n\\uf076 Step 11: Now go back to get that Scan, Print Release, Print Cloud \\nFiles & Copy Operations. \\uf076 Now All the Setups completed successfully to use MFP. \\n     Synappx Go Display Agent \\nLogin with the any stack with the user id provided. \\n \\nNow, after Downloading this Synappx GO Display Agent into \\nyour Device OR PC.'), Document(metadata={'file_name': 'SHARP Synappx GO Documentation (2)'}, page_content='\\uf076                  \\n Step 4    Step 5 Step 6 \\n\\uf076                   \\n Step 7      Step 8  Step 9 \\n \\n\\uf076                  \\n Step 10      Step 11 \\n \\n \\nAfter installing the Mobile application these are the steps to be followed \\nto connect the mobile application to your MFP. \\n\\uf076 Step 1: Click on the login to continue. \\n\\uf076 Step 2: Give the login id which you have given in web page to \\ndownload the Synappx Go MFP into your PC. \\nAfter Login Successfully. \\n\\uf076 Step 3: Chick the Menu button on left top and go to settings. \\n\\uf076 Step 4: Then, you can see the many options listed here this page is \\nto Setup the NFC tag Manually if you didnt have NFC tag. \\nTag five times on bottom empty space you will find the Step 4.  \\n \\n\\uf076 Step 5:  Here you can see that you have to paste NFC tag Valid Id \\nto perform the Print, Share/Display and Checkin Operations. \\n\\uf076 Step 6: To get that ID go to the Browser from the same mobile \\nand search for UUID GENERATOR or uuidgenerator.net and'), Document(metadata={'file_name': 'SHARP Synappx GO Documentation (2)'}, page_content='stack as well as same user id to inter connect with MFP, Agent and \\nMobile application. \\nLogin steps, \\nLogin Synappx Go User Experience \\n \\nAs an alternative to the more fully featured, users have an \\noption to use the Continue Login (licensed) version and \\nNo login version. Both the licensed and login \\n(subscription version) Synappx Go are available from the \\nsame Synappx Go mobile app downloaded from the Apple \\nApp Store or Google Play site. \\n \\nBefore using the Continue Login (licensed) version of \\nSynappx Go, ensure the Sharp MFP you will use has been \\nconfigured to support this feature. You should be able to \\nselect the Synappx Go  No Login icon from the MFP. See \\ndetails below for more information. \\n \\nTo use the Synappx Go Login version: \\n  \\n \\n\\uf0b7 Download the Synappx Go iOS or Android app from the Apple \\nor Google app stores. \\n\\uf0b7 Select Continue Log In. \\n\\uf0b7 Agree to the End User License Agreement. \\n\\uf0b7 The Home screen is displayed on your mobile. \\n \\n\\uf076                      \\n Step 1    Step 2      Step 3')]\n",
      "LLM Response:\n",
      "content='The query is relevant to the document.\\n\\nAccording to the document, to download and install the MFP agent, follow these steps:\\n\\n1. Go to the Synappx Collaboration HUB Installer page (page 3) and click on \"SNMP Configuration\".\\n2. Enter the IP address range of your Sharp MFPs in the IP Range start and End fields.\\n3. Click on \"Download Now\" to start downloading the application.\\n4. After downloading, extract the file and open it to start installing the application (page 5).\\n5. Follow the installation steps as described in the document.\\n\\nPage numbers: 3-5' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-01-16T06:59:06.158143Z', 'done': True, 'done_reason': 'stop', 'total_duration': 96414559100, 'load_duration': 6693817700, 'prompt_eval_count': 1631, 'prompt_eval_duration': 72312000000, 'eval_count': 129, 'eval_duration': 17160000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-3ef9d225-16b6-4431-8b77-b6ab2664da9a-0' usage_metadata={'input_tokens': 1631, 'output_tokens': 129, 'total_tokens': 1760}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print('starting with vector store')\n",
    "    vector_store = build_vector_store(\"./Document/test\")\n",
    "    print('done with vector store')\n",
    "    user_query = \"How to download and install MFP agent...?\" \n",
    "    print('started with llm')\n",
    "    response = query_llm(vector_store, user_query)\n",
    "    print(\"LLM Response:\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content='To understand how to answer a user\\'s context-based search request for \"helpful AI assistant\" using Synapse Search Engine, you need to follow the steps below:\\n\\n1. Read the text provided in the context and identify the keywords or phrases relevant to your query.\\n2. Check if the searched term is mentioned anywhere else in the article or within the document. This will help you narrow down your search results.\\n3. Check the website\\'s URL for any other relevant pages that might be useful.\\n4. Consider the date of publication and see if it matches the time frame for your query.\\n5. Look for related keywords or phrases in the article to help you understand the context further.\\n6. If necessary, use additional keyword research tools like Google Trends or SEMrush to gain more insights into the topic and potential search volume.\\n7. Use Synapse Search Engine\\'s advanced features, such as synonyms, reverse lookup, or phrase match, to refine your results and find the most relevant answers.\\n8. If you\\'re still unsure about what to do next, consult with a professional who can help you identify the best approach for your specific context-based search request.' additional_kwargs={} response_metadata={'model': 'tinyllama', 'created_at': '2024-11-28T07:40:44.619601Z', 'done': True, 'done_reason': 'stop', 'total_duration': 850243143700, 'load_duration': 1181269500, 'prompt_eval_count': 1570, 'prompt_eval_duration': 706653000000, 'eval_count': 259, 'eval_duration': 142126000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-2a0df05e-e8af-4455-a8cd-fd6f2dffdd05-0' usage_metadata={'input_tokens': 1570, 'output_tokens': 259, 'total_tokens': 1829}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to execute scan functionality..?\n",
    "content='**The query is relevant to the document.\\n\\nTo execute the scan functionality, follow these steps:\\n\\n1. Tap your phone to scan a file to yourself (via email), email distribution lists, and popular cloud storage services.\\n2. Create contactless copy jobs from your mobile phone and save your favorite copy settings.\\n3. After installing the Mobile application, go to Step 6 in the setup process: To get that ID go to the Browser from the same mobile and search for UUID GENERATOR or uuidgenerator.net and copy the latest UUID and Paste it on that Step 5 page or paste it on that Print, Share/Display and Checkin and go to the bottom and save that given id.\\n\\nNote that the document does not provide a detailed explanation of how to execute the scan functionality. However, it mentions that you can tap your phone to scan a file and create contactless copy jobs from your mobile phone.**' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2024-12-02T11:37:09.043607Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4387881640100, 'load_duration': 510538600, 'prompt_eval_count': 1517, 'prompt_eval_duration': 4003514000000, 'eval_count': 183, 'eval_duration': 383848000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-c07c60cb-09d8-480a-9282-973b7d20b17d-0' usage_metadata={'input_tokens': 1517, 'output_tokens': 183, 'total_tokens': 1700}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content='The query is relevant to the document.\\n\\nTo execute Scan, follow these steps:\\n\\n1. Tap your phone to scan a file to yourself (via email), email distribution lists, and popular cloud storage services.\\n2. The mobile application will automatically detect the scanned document and allow you to save it to your preferred location.\\n\\nNote that the exact steps may vary depending on the specific device and operating system being used.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2024-12-02T12:22:32.3179432Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1986017443500, 'load_duration': 12094291700, 'prompt_eval_count': 1516, 'prompt_eval_duration': 1838643000000, 'eval_count': 82, 'eval_duration': 135270000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-ce774771-29fb-4421-be55-aff9e2122983-0' usage_metadata={'input_tokens': 1516, 'output_tokens': 82, 'total_tokens': 1598}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
